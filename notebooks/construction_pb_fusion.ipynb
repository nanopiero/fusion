{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanopiero/fusion/blob/master/notebooks/construction_pb_fusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construction problème fusion\n"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mU0zdFYCLdgR"
      },
      "outputs": [],
      "source": [
        "# Imports des bibliothèques utiles\n",
        "# pour l'IA\n",
        "import torch\n",
        "# pour les maths\n",
        "import numpy as np\n",
        "# pour afficher des images et des courbes\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from random import randint\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def voir_mat(data2, fig, min_scale=-10,max_scale=70):\n",
        "\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.imshow(data2, interpolation='nearest', cmap=plt.cm.rainbow) #cmap=plt.cm.ocean)\n",
        "    plt.clim(min_scale,max_scale)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def voir_tens(image, fig, min_scale=-1,max_scale=1):\n",
        "    im=image[0,0,:,:].numpy()\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.imshow(im, interpolation='nearest',  cmap=plt.cm.rainbow) #cmap=plt.cm.ocean)\n",
        "    plt.clim(min_scale,max_scale)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def conc(image1,image2,dim=3):\n",
        "    return torch.cat((image1,image2), dim) #, out=None)\n",
        "\n",
        "def multi_conc(L,dim=1,ecart=5, min_scale=0.5):\n",
        "    image1=L[0]\n",
        "    for i in range(1, len(L)):\n",
        "        if dim==1:\n",
        "            sep=  min_scale + 0*image1[:,0:ecart]\n",
        "        elif dim==0:\n",
        "            sep=  min_scale + 0*image1[0:ecart,:]\n",
        "        image1=conc(image1,sep,dim)\n",
        "        image2=L[i]\n",
        "        image1=conc(image1,image2,dim=dim)\n",
        "    return image1\n",
        "\n",
        "def images_from_tenseur(tens, k=0):\n",
        "    len_batch=tens.shape[0]\n",
        "    L=[]\n",
        "    for i in range(len_batch):\n",
        "        L.append(tens[i,k,:,:])\n",
        "    return L\n",
        "\n",
        "def voir_batch2D(tens, nx, fig,k=0, min_scale=-10,max_scale=1):\n",
        "    s = 0.5*(min_scale + max_scale)\n",
        "    L=images_from_tenseur(tens,k)\n",
        "    image1=multi_conc(L[0:nx],dim=1, min_scale=s)\n",
        "    for i in range(1,int(len(L)/nx)):\n",
        "        image2=multi_conc(L[i*nx:(i+1)*nx],dim=1, min_scale=s)\n",
        "        image1=multi_conc([image1,image2],dim=0, min_scale=s)\n",
        "    voir_mat(image1, fig, min_scale,max_scale)\n",
        "\n",
        "\n",
        "#############################################################\n",
        "#pour la génération des images    ###########################\n",
        "#############################################################\n",
        "\n",
        "def simu_rec(image, L,l,  fields=0):\n",
        "    channels,size,size2=image.size()\n",
        "    rec= torch.zeros(channels,size,size2)\n",
        "    #out = 0*(image.clone())\n",
        "    vertical=np.random.binomial(1,0.5)==1\n",
        "    if vertical:\n",
        "        width=l\n",
        "        height=L\n",
        "    else:\n",
        "        width=L\n",
        "        height=l\n",
        "\n",
        "    top=randint(0, size-height)\n",
        "    left=randint(0, size-width)\n",
        "    rec[fields,top:top+height,left:left+width]=  np.random.uniform(0,0.4)   #0.1\n",
        "    image=image + rec\n",
        "    return image\n",
        "\n",
        "def simu_noisy_rec(image, L,l,  fields=0):\n",
        "    channels,size,size2=image.size()\n",
        "    rec= torch.zeros(channels,size,size2)\n",
        "    #out = 0*(image.clone())\n",
        "    vertical=np.random.binomial(1,0.5)==1\n",
        "    if vertical:\n",
        "        width=l\n",
        "        height=L\n",
        "    else:\n",
        "        width=L\n",
        "        height=l\n",
        "\n",
        "    top=randint(0, size-height)\n",
        "    left=randint(0, size-width)\n",
        "    rec[fields,top:top+height,left:left+width]= np.random.uniform(0,0.4)  #0.1\n",
        "    noise=torch.randn(channels,size,size2)\n",
        "    noise=noise*(noise>0).float()\n",
        "    rec=noise*rec\n",
        "    image=image + rec\n",
        "    return image\n",
        "\n",
        "def simu_disc(image, f, radius=15, fields=0 ):  #radial decrease function  #or 12\n",
        "    channels,size,size2=image.size()\n",
        "    center=np.array([randint(radius, size-radius) , randint(radius, size-radius) ])\n",
        "    npdisc= f( ((np.arange(0,64)*np.ones([size,size])) - center[0])**2 + (np.transpose(np.arange(0,64)*np.ones([size,size]))-center[1])**2  , radius)\n",
        "    npdisc=np.random.uniform(0.6,1.) * npdisc  #variation on intensity\n",
        "    image[fields,:,:] = image[fields,:,:] + torch.from_numpy(npdisc).float()   #matrice des distances < rayon\n",
        "    return image\n",
        "\n",
        "def simu_disc_with_cond(image, f, radius=15, fields=0, f2 = lambda a,x  : ((np.sin(3.1 * a/x**2)))*(a < x**2) ):  #radial decrease function  #or 12\n",
        "    channels,size,size2=image.size()\n",
        "    center=np.array([randint(radius-5, size-radius+2) , randint(radius-2, size-radius+5) ])\n",
        "    npdisc= f( ((np.arange(0,64)*np.ones([size,size])) - center[0])**2 + (np.transpose(np.arange(0,64)*np.ones([size,size]))-center[1])**2  , radius)\n",
        "    npdisc=np.random.uniform(0.6,1.) * npdisc  #variation on intensity\n",
        "    image[0,:,:] = image[0,:,:] + torch.from_numpy(npdisc).float()   #matrice des distances < rayon\n",
        "    if (radius >= 10) and (radius <= 14):\n",
        "        npdon = f2( ((np.arange(0,64)*np.ones([size,size])) - center[0])**2 + (np.transpose(np.arange(0,64)*np.ones([size,size]))-center[1])**2  , radius)\n",
        "        image[1,:,:] = image[1,:,:] + torch.from_numpy(npdon).float()**2\n",
        "    return image\n",
        "\n",
        "\n",
        "def simu_square(image, f, diag=15, fields=0 ):  #radial decrease function  #or 12\n",
        "    channels,size,size2 = image.size()\n",
        "    center=np.array([randint(diag, size-diag) , randint(diag, size-diag) ])\n",
        "\n",
        "    npsquare = f(  np.abs(np.arange(0,64)*np.ones([size,size]) - center[0]) + \\\n",
        "                   np.abs(np.transpose(np.arange(0,64)*np.ones([size,size]))-center[1]), diag)\n",
        "#    npsquare = np.abs(np.arange(0,64)*np.ones([size,size]) - center[0])\n",
        "    npsquare = np.random.uniform(0.6,1.) * npsquare  #variation on intensity\n",
        "    image[fields,:,:] = image[fields,:,:] + torch.from_numpy(npsquare).float()   #matrice des distances < rayon\n",
        "    return image\n",
        "\n",
        "\n",
        "def plot_pairs(image, f = lambda x : x**2):\n",
        "    horizontal = (torch.randint(0,2,(1,)) > 0.5).item()\n",
        "#    print(horizontal)\n",
        "    dist = torch.randint(1,32, (1,)).item()\n",
        "    if horizontal :\n",
        "        ordo = torch.randint(0, 64, (1,)).item()\n",
        "        absi = torch.randint(0, 64 - dist, (1,)).item()\n",
        "        image[1, ordo, absi:(absi + dist + 1)] \\\n",
        "            += 0.1 + torch.mean(f(image[0, ordo, absi:(absi + dist + 1)]))\n",
        "    else :\n",
        "        ordo = torch.randint(0, 64 - dist, (1,)).item()\n",
        "        absi = torch.randint(0, 64, (1,)).item()\n",
        "        image[1, ordo:ordo+dist+1, absi] \\\n",
        "            += 0.1 + torch.mean(f(image[0, ordo:ordo+dist+1, absi]))\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "def make_image(rec, noisy_rec ,disc,square=0., pola=[0]):\n",
        "    image=torch.zeros([1,64, 64])\n",
        "    image = generate_noise(image, lambda_rec=rec, lambda_noisy_rec = noisy_rec,lambda_disc = disc, lambda_square = square, pola= pola)\n",
        "    return image\n",
        "\n",
        "def make_image_with_cond(rec, noisy_rec ,disc,square=0., pola=[0]):\n",
        "    image = torch.zeros([2, 64, 64])\n",
        "    image = generate_noise_with_cond(image, lambda_rec=rec, lambda_noisy_rec = noisy_rec,lambda_disc = disc, lambda_square = square, pola= pola)\n",
        "    return image\n",
        "\n",
        "def make_batch(batch_size, rec, noisy_rec ,disc, square=0., pola=[0] ):\n",
        "    out = make_image(rec, noisy_rec ,disc , square, pola ).unsqueeze(0)\n",
        "    for i in range(batch_size-1):\n",
        "        new=make_image(rec, noisy_rec ,disc, square, pola).unsqueeze(0)\n",
        "        out=torch.cat((out,new), dim=0)\n",
        "    return out\n",
        "\n",
        "def make_batch_with_cond(batch_size, rec, noisy_rec ,disc, square=0.):\n",
        "    out = make_image_with_cond(rec, noisy_rec ,disc , square).unsqueeze(0)\n",
        "    for i in range(batch_size-1):\n",
        "        new=make_image_with_cond(rec, noisy_rec ,disc, square).unsqueeze(0)\n",
        "        out=torch.cat((out,new), dim=0)\n",
        "    return out\n",
        "\n",
        "def make_image_with_pairs(rec, freq_integrated_signals, noisy_rec ,disc,square=0., pola=[0]):\n",
        "    image=torch.zeros([1,64, 64])\n",
        "    image = generate_noise_and_pairs(image, lambda_pairs=freq_integrated_signals,\n",
        "                                     lambda_rec=rec, lambda_noisy_rec=noisy_rec,\n",
        "                                     lambda_disc=disc, lambda_square=square,\n",
        "                                     pola= pola)\n",
        "    return image\n",
        "\n",
        "def make_batch_with_pairs(batch_size, freq_integrated_signals, rec, noisy_rec,\n",
        "                                disc, square=0., pola=[0]):\n",
        "    out=make_image_with_pairs(rec, freq_integrated_signals, noisy_rec,\n",
        "                              disc , square, pola ).unsqueeze(0)\n",
        "    for i in range(batch_size - 1):\n",
        "        new=make_image_with_pairs(rec, freq_integrated_signals, noisy_rec, disc, square, pola).unsqueeze(0)\n",
        "        out=torch.cat((out,new), dim = 0)\n",
        "    return out\n",
        "\n",
        "\n",
        "##############################################################################################\n",
        "################################       spécifique au TP     ##################################\n",
        "\n",
        "def gen(n):  #exercice 1 partie 1\n",
        "  target = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.002)\n",
        "  noise =  make_batch(n, rec = 0.0003, noisy_rec= 0.0003, disc = 0.)\n",
        "  return  target + noise, target     #bruit additif trivial\n",
        "\n",
        "def gen_noise2noise(n):\n",
        "  target = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.002)\n",
        "  noise1 =  make_batch(n, rec = 0.0005, noisy_rec= 0.0005, disc = 0.)\n",
        "  noise2 =  make_batch(n, rec = 0.0005, noisy_rec= 0.0005, disc = 0.)\n",
        "  return  target + noise1, target + noise2\n",
        "\n",
        "def gen1_NES(n):\n",
        "  noisy_image = make_batch(n, rec = 0.0003, noisy_rec= 0.0003, disc = 0.002)\n",
        "  return  noisy_image\n",
        "\n",
        "def gen2_NES(n):\n",
        "  noise1 =  make_batch(n, rec = 0.0003, noisy_rec= 0.0003, disc = 0.)\n",
        "  return  noise1\n",
        "\n",
        "\n",
        "def gen_proba(n):\n",
        "  target1 = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.001)\n",
        "  m1 = torch.normal(target1**2, 0.2*target1)\n",
        "  input = target1\n",
        "  target =   m1\n",
        "  return  input, target\n",
        "\n",
        "def gen_ponct(n, p = 0.01):\n",
        "  input = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.001)\n",
        "  fulltarget = 2*input**2\n",
        "  sb = torch.bernoulli(0*fulltarget + p)         # En moyenne,2% des pixels sont couverts par une mesure ponctuelle\n",
        "\n",
        "  #cible fragmentaire\n",
        "  target = fulltarget*(sb) + (-1)*(1 - sb)\n",
        "\n",
        "  return  input, target, fulltarget\n",
        "\n",
        "\n",
        "def gen_condDCGAN(n, p = 0.01):\n",
        "  x = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.001, square = 0.)\n",
        "  fulltarget = x #2*x**2\n",
        "#  sb = (make_batch(n, rec = 0., noisy_rec= 0., disc = p, square = 0.)> 0.1\n",
        "  sb = torch.bernoulli(0*fulltarget + p)         # En moyenne,2% des pixels sont couverts par une mesure ponctuelle\n",
        "  #cond (ex. cible fragmentaire)\n",
        "  y = fulltarget*sb + (-0.1)*(1 - sb)\n",
        "\n",
        "  z = torch.randn(*fulltarget.size())\n",
        "  return  x, y, z\n",
        "\n",
        "\n",
        "def gen_DCGAN(n, lambda_rec = 0.):\n",
        "  x = make_batch(n, rec = lambda_rec, noisy_rec= 0., disc = 0.001, square = 0.)\n",
        "  fulltarget = x #2*x**2\n",
        "\n",
        "  z = torch.randn(*fulltarget.size())\n",
        "  return  x, z\n",
        "\n",
        "\n",
        "def gensquare_condDCGAN(n, p = 0.01):\n",
        "  x = make_batch(n, rec = 0., noisy_rec= 0., disc = 0., square = 0.001)\n",
        "  fulltarget = x #2*x**2\n",
        "  sb = torch.bernoulli(0*fulltarget + p)         # En moyenne,2% des pixels sont couverts par une mesure ponctuelle\n",
        "  #cond (ex. cible fragmentaire)\n",
        "  y = fulltarget*sb + (-1)*(1 - sb)\n",
        "\n",
        "  z = torch.randn(*fulltarget.size())\n",
        "  return  x, y, z\n",
        "\n",
        "def gen_cycleGAN(n, lambda_disc = 0.001, lambda_square = 0.001):\n",
        "  Adiscs = make_batch(n, rec = 0., noisy_rec= 0., disc = lambda_disc, square = 0.)\n",
        "  Bsquares = make_batch(n, rec = 0., noisy_rec= 0., disc = 0., square = lambda_square)\n",
        "  return  Adiscs, Bsquares\n",
        "\n",
        "\n",
        "def gen_mixt(n, p = 0.02):\n",
        "  target1 = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.001)\n",
        "  target2 = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.001)\n",
        "  s1 = 0.4*target1  #premier type de cellule: signal-cible faible\n",
        "  s2 = 1.6*target2  #second type: signal-cible fort\n",
        "  sb = torch.bernoulli(0*target1 + p)         # En moyenne,2% des pixels sont couverts par une mesure ponctuelle\n",
        "\n",
        "  #noise =  make_batch(n, rec = 0.0003, noisy_rec= 0.0003, disc = 0.)\n",
        "\n",
        "  input = target1 + target2\n",
        "  fulltarget =   s1 + s2\n",
        "\n",
        "  #cible fragmentaire\n",
        "  target = fulltarget*sb + (-1)*(1 - sb)\n",
        "\n",
        "  return  input, target, fulltarget\n",
        "\n",
        "\n",
        "  def simu_1disc(image, mean, sigma, f, radius=15, fields=0 ):  #radial decrease function  #or 12\n",
        "    channels,size,size2=image.size()\n",
        "    center=np.array([randint(radius, size-radius) , randint(radius, size-radius) ])\n",
        "    npdisc= f( ((np.arange(0,64)*np.ones([size,size])) - center[0])**2 + (np.transpose(np.arange(0,64)*np.ones([size,size]))-center[1])**2  , radius)\n",
        "    npdisc = torch.from_numpy(npdisc).float()\n",
        "    noise = torch.randn(channels,size,size2)\n",
        "    npdisc = (mean + sigma*noise)* npdisc   #bruitage du disque\n",
        "    image[fields,:,:] = image[fields,:,:] + npdisc   #matrice des distances < rayon\n",
        "    return image\n",
        "\n",
        "def make_image2():\n",
        "    image=torch.zeros([1,64, 64])\n",
        "    f = lambda a,x  : (a < x**2)\n",
        "    r = randint(5,10)\n",
        "    rplus = randint(5,8)\n",
        "    md0= np.random.uniform(0,1)\n",
        "    md1= np.random.uniform(0,1)\n",
        "    image=simu_1disc(image, md0, 0, f  ,radius = r)\n",
        "    image=simu_1disc(image, md1, 0, f  ,radius = r+rplus)\n",
        "#    L=randint(50,60)\n",
        "#    l=randint(2,10)\n",
        "#    image= simu_rec(image,L,l)\n",
        "    return image.unsqueeze(0), torch.tensor(md0).reshape((1,1))\n",
        "\n",
        "def gen_paires(batch_size):\n",
        "    out0,y0=make_image2()\n",
        "    out1,y1=make_image2()\n",
        "\n",
        "    for i in range(batch_size-1):\n",
        "        new0,newy0=make_image2()\n",
        "        out0=torch.cat((out0,new0), dim=0)\n",
        "        y0=torch.cat((y0,newy0), dim=0)\n",
        "        new1,newy1=make_image2()\n",
        "        out1=torch.cat((out1,new1), dim=0)\n",
        "        y1=torch.cat((y1,newy1), dim=0)\n",
        "    return out0,out1, (y0<y1).int(), y0, y1\n",
        "\n",
        "\n",
        "def gen_image_with_integrated_signals(batch_size, p):\n",
        "    freq_integrated_signals = 0.005\n",
        "    image = make_batch_with_pairs(batch_size, freq_integrated_signals,\n",
        "                                  0, 0 ,0.001, square=0., pola=[0] )\n",
        "    full_target = image[:,[0],:,:] #2*x**2\n",
        "    sb = torch.bernoulli(0*full_target + p)         # En moyenne,2% des pixels sont couverts par une mesure ponctuelle\n",
        "    #cond (ex. cible fragmentaire)\n",
        "    partial_target = full_target*sb + (-1)*(1 - sb)\n",
        "    integrated_signals = image[:,[1],:,:]\n",
        "\n",
        "    return full_target, partial_target, integrated_signals\n",
        "\n",
        "\n",
        "#def gen_pointnet(n):\n",
        "#  target = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.0005)\n",
        "#  noise =  make_batch(n, rec = 0.001, noisy_rec= 0., disc = 0.)\n",
        "#  return  target + noise, target     #bruit additif trivial\n",
        "\n",
        "\n",
        "def gen_pointnet(n, N, M):\n",
        "  x = make_batch(n, rec = 0.001, noisy_rec= 0., disc = 0.)\n",
        "  y = make_batch(n, rec = 0., noisy_rec= 0., disc = 0.0005)\n",
        "  x = x + y\n",
        "  y = (y > 0).long()\n",
        "\n",
        "  # points\n",
        "  xis = []\n",
        "  yis = []\n",
        "  for i in range(x.shape[0]):\n",
        "    xi, yi = get_random_xy_triplets(x[i].squeeze(0), y[i].squeeze(0), N, M)\n",
        "    xis.append(xi.unsqueeze(0))\n",
        "    yis.append(yi.unsqueeze(0))\n",
        "  ux = torch.transpose(torch.cat(xis, dim=0),1,2)\n",
        "  # ux[:,2] += torch.rand(1).cuda()\n",
        "  uy = torch.transpose(torch.cat(yis, dim=0),1,2)\n",
        "\n",
        "  # Normalisation / réduction de y:\n",
        "  ux[:,:2,:] /= 64\n",
        "  uy = uy[:,2,:]\n",
        "  xy = torch.cat((ux[:,:2,:], uy.unsqueeze(1)), dim=1)\n",
        "\n",
        "  return  x, y, ux, uy, xy\n",
        "\n",
        "\n",
        "\n",
        "def generate_noise(image, lambda_rec=0.001 ,lambda_noisy_rec = 0.001, lambda_disc = 0.001, lambda_square = 0., pola=[0,0.5,0.1]):\n",
        "    for k in range(np.random.poisson(lambda_disc*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_disc(image, lambda a,x  : (0.39 - 0.36*a/x**2)*(a < x**2) ,radius = r)  #0.47 pour avoir 40 dB\n",
        "    for k in range(np.random.poisson(lambda_square*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_square(image, lambda a,x  : (0.5 - 0.45*a/x)*(a < x) , diag = r)  #0.47 pour avoir 40 dB\n",
        "#        print(r)\n",
        "\n",
        "    for i in range(np.random.poisson(lambda_rec*64*64)):\n",
        "        L=randint(20,50)\n",
        "        l=randint(2,10)\n",
        "        image= simu_rec(image,L,l)\n",
        "    for j in range(np.random.poisson(lambda_noisy_rec*64*64)):\n",
        "        L=randint(10,30)\n",
        "        l=randint(10,30)\n",
        "        image= simu_noisy_rec(image,L,l)\n",
        "        # 0.3*np.exp(-0.1 * a/x)*(a < x**2)  #image=simu_disque(image, lambda a,x  : 1.0*(a < x**2)  )\n",
        "    if pola[0]==1:      #add a pseudo pola field\n",
        "        image_pola = generate_pola(image,pola)\n",
        "        image=torch.cat([image,image_pola],dim=0)\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_noise_with_cond(image, lambda_rec=0.001 ,lambda_noisy_rec = 0.001, lambda_disc = 0.001, lambda_square = 0., pola=[0,0.5,0.1]):\n",
        "    for k in range(np.random.poisson(lambda_disc*64*64)):\n",
        "        r = randint(6,18)\n",
        "        image=simu_disc_with_cond(image, lambda a,x  : (0.39 - 0.36*a/x**2)*(a < x**2) ,radius = r)  #0.47 pour avoir 40 dB\n",
        "    for k in range(np.random.poisson(lambda_square*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_square(image, lambda a,x  : (0.5 - 0.45*a/x)*(a < x) , diag = r)  #0.47 pour avoir 40 dB\n",
        "#        print(r)\n",
        "\n",
        "    for i in range(np.random.poisson(lambda_rec*64*64)):\n",
        "        L=randint(20,50)\n",
        "        l=randint(2,10)\n",
        "        image= simu_rec(image,L,l)\n",
        "    for j in range(np.random.poisson(lambda_noisy_rec*64*64)):\n",
        "        L=randint(10,30)\n",
        "        l=randint(10,30)\n",
        "        image= simu_noisy_rec(image,L,l)\n",
        "        # 0.3*np.exp(-0.1 * a/x)*(a < x**2)  #image=simu_disque(image, lambda a,x  : 1.0*(a < x**2)  )\n",
        "    return image\n",
        "\n",
        "\n",
        "def generate_noise_and_pairs(image, lambda_pairs=0.01, lambda_rec=0.001,\n",
        "                             lambda_noisy_rec=0.001, lambda_disc=0.001,\n",
        "                             lambda_square=0., pola=[0,0.5,0.1]):\n",
        "    for k in range(np.random.poisson(lambda_disc*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_disc(image, lambda a,x  : (0.39 - 0.36*a/x**2)*(a < x**2) ,radius = r)  #0.47 pour avoir 40 dB\n",
        "    for k in range(np.random.poisson(lambda_square*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_square(image, lambda a,x  : (0.5 - 0.45*a/x)*(a < x) , diag = r)  #0.47 pour avoir 40 dB\n",
        "#        print(r)\n",
        "    for i in range(np.random.poisson(lambda_rec*64*64)):\n",
        "        L=randint(20,50)\n",
        "        l=randint(2,10)\n",
        "        image= simu_rec(image,L,l)\n",
        "    for j in range(np.random.poisson(lambda_noisy_rec*64*64)):\n",
        "        L=randint(10,30)\n",
        "        l=randint(10,30)\n",
        "        image = simu_noisy_rec(image,L,l)\n",
        "        # 0.3*np.exp(-0.1 * a/x)*(a < x**2)  #image=simu_disque(image, lambda a,x  : 1.0*(a < x**2)  )\n",
        "    # on ajoute le deuxième canal où les échanges entre signaux seront\n",
        "    # représentés\n",
        "\n",
        "    image2 = torch.zeros([1,64, 64])\n",
        "    image = torch.cat([image, image2], dim = 0 )\n",
        "\n",
        "    for j in range(np.random.poisson(lambda_pairs * 64 * 64)):\n",
        "        image = plot_pairs(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "5zHe5if9b8Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################################################################\n",
        "###################################### Fusion & CML (needs numba) ###################################\n",
        "\n",
        "from numba import jit\n",
        "from numpy.random import randint\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def get_equation(coords_1, coords_2):\n",
        "  # rustine pour éviter les pbs. lon lat étant données à 10-5 près:\n",
        "  eps = 10**-5\n",
        "  if coords_2[0] == coords_1[0] :\n",
        "      m = (coords_2[1] - coords_1[1]) / (eps + coords_2[0] - coords_1[0])\n",
        "  elif coords_2[1] == coords_1[1] :\n",
        "      m = (eps + coords_2[1] - coords_1[1]) / (coords_2[0] - coords_1[0])\n",
        "  else:\n",
        "      m = (coords_2[1] - coords_1[1]) / (coords_2[0] - coords_1[0])\n",
        "  a =  -m\n",
        "  b =  1\n",
        "  c =  m*coords_1[0]  - coords_1[1]\n",
        "  return a,b,c\n",
        "\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def get_dists(coords_1, coords_2, matrix):\n",
        "\n",
        "  \"\"\"\n",
        "  Compute intersection length between\n",
        "  [coords_1, coords_2] and pixel_ij\n",
        "  should have: coords_1[0] < coords_2[0]\n",
        "  \"\"\"\n",
        "  a, b, c = get_equation(coords_1, coords_2)\n",
        "  # print(\"equation :\", a, b ,c)\n",
        "  N,M = matrix.shape\n",
        "  # Indx = np.arange(0,M).reshape(1,M).repeat(N,axis = 0)\n",
        "  # Indy = np.arange(N-1,-1,-1).reshape(N,1).repeat(M,axis = 1)\n",
        "\n",
        "  Indx = np.arange(0,M).repeat(N).reshape(M,N).transpose((1,0))\n",
        "  Indy = np.arange(N-1,-1,-1).repeat(M).reshape(N,M)\n",
        "\n",
        "  # print(Indx == np.arange(0,M).repeat(N).reshape(M,N).transpose((1,0)))\n",
        "  # print(Indy == np.arange(N-1,-1,-1).repeat(M).reshape(N,M))\n",
        "  # raise Exception('')\n",
        "\n",
        "  inds_1 = (np.ceil(coords_1[0]), np.ceil(coords_1[1]))\n",
        "  inds_2 = (np.ceil(coords_2[0]), np.ceil(coords_2[1]))\n",
        "\n",
        "  coord_l = min(coords_1[0], coords_2[0])\n",
        "  coord_r = max(coords_1[0], coords_2[0])\n",
        "  coord_d = min(coords_1[1], coords_2[1])\n",
        "  coord_u = max(coords_1[1], coords_2[1])\n",
        "\n",
        "  eps = 10**-6\n",
        "  ind_l = int(np.floor(coord_l))\n",
        "  ind_r = int(np.floor(coord_r - eps))\n",
        "  ind_d = int(np.floor(coord_d))\n",
        "  ind_u = int(np.floor(coord_u - eps))\n",
        "\n",
        "\n",
        "  # for each pixel i,j: the sign of Mld[i,j]\n",
        "  # gives the relative position of the left/down corner\n",
        "  # wrt the line ax + by + c = 0\n",
        "  Mld = (a * Indx + b * Indy + c)\n",
        "  Mrd = (a * (Indx + 1) + b * Indy + c)\n",
        "  Mlu = (a * Indx + b * (Indy + 1) + c)\n",
        "  Mru = (a * (Indx + 1) + b * (Indy + 1) + c)\n",
        "\n",
        "  # intersections with l/r edges :\n",
        "  Xl = (Indx + 0.) #.astype(float)\n",
        "  Xr = (Indx + 1.) #.astype(float)\n",
        "  Yl = (- a * Indx - c) / b\n",
        "  Yr = (- a * (Indx + 1) - c) / b\n",
        "\n",
        "\n",
        "  # intersections with u/d edges :\n",
        "  Xd = (- b * Indy - c) / a\n",
        "  Xu = (- b * (Indy + 1) - c) / a\n",
        "  Yd = (Indy + 0.) #.astype(float)\n",
        "  Yu = (Indy + 1.) #.astype(float)\n",
        "\n",
        "  # case of pixels 1 & 2\n",
        "  if a >= 0:\n",
        "    Xl[N - 1 - ind_u,ind_l] = coord_l\n",
        "    Xu[N - 1 - ind_u,ind_l] = coord_l\n",
        "\n",
        "    Xr[N - 1 - ind_d,ind_r] = coord_r\n",
        "    Xd[N - 1 - ind_d,ind_r] = coord_r\n",
        "\n",
        "    Yu[N - 1 - ind_u,ind_l] = coord_u\n",
        "    Yl[N - 1 - ind_u,ind_l] = coord_u\n",
        "\n",
        "    Yd[N - 1 - ind_d,ind_r] = coord_d\n",
        "    Yr[N - 1 - ind_d,ind_r] = coord_d\n",
        "\n",
        "\n",
        "  else:\n",
        "    Xl[N - 1 - ind_d,ind_l] = coord_l\n",
        "    Xd[N - 1 - ind_d,ind_l] = coord_l\n",
        "\n",
        "    Xr[N - 1 - ind_u,ind_r] = coord_r\n",
        "    Xu[N - 1 - ind_u,ind_r] = coord_r\n",
        "\n",
        "    Yu[N - 1 - ind_u,ind_r] = coord_u\n",
        "    Yr[N - 1 - ind_u,ind_r] = coord_u\n",
        "\n",
        "    Yd[N - 1 - ind_d,ind_l] = coord_d\n",
        "    Yl[N - 1 - ind_d,ind_l] = coord_d\n",
        "\n",
        "\n",
        "  # Building distance matrix\n",
        "  Dists = 0. * Xl\n",
        "  # lu : path between lu, ld & lu, ru\n",
        "  Mask = ((Mlu * Mld < 0) * (Mlu * Mru <= 0))\n",
        "  Dists += np.sqrt((Xl - Xu)**2 + (Yl - Yu)**2) * Mask\n",
        "\n",
        "  # lr : path between lu, ld & ru, rd\n",
        "  Mask = (Mlu * Mld < 0) * (Mru * Mrd < 0)\n",
        "  Dists += np.sqrt((Xl - Xr)**2 + (Yl - Yr)**2) * Mask\n",
        "\n",
        "  # ld : path between lu, ld & ld, rd\n",
        "  Mask = (Mlu * Mld < 0) * (Mld * Mrd <= 0)\n",
        "  Dists += np.sqrt((Xl - Xd)**2 + (Yl - Yd)**2) * Mask\n",
        "\n",
        "  # ur : path between lu, ru & ru, rd\n",
        "  Mask = (Mlu * Mru <= 0) * (Mru * Mrd < 0)\n",
        "  Dists += np.sqrt((Xu - Xr)**2 + (Yu - Yr)**2) * Mask\n",
        "\n",
        "  # ud : path between lu, ru & ld, rd\n",
        "  Mask = (Mlu * Mru <= 0) * (Mld * Mrd <= 0)\n",
        "  Dists += np.sqrt((Xu - Xd)**2 + (Yu - Yd)**2) * Mask\n",
        "\n",
        "  # rd : path between ld, rd & ru, rd\n",
        "  Mask = (Mld * Mrd <= 0) * (Mru * Mrd < 0)\n",
        "  Dists += np.sqrt((Xr - Xd)**2 + (Yr - Yd)**2) * Mask\n",
        "\n",
        "  # clean outside the segment :\n",
        "  Mask = (Indx >= ind_l) * (Indx <= ind_r)\n",
        "  Dists *= Mask\n",
        "\n",
        "  Mask = (Indy >= ind_d) * (Indy <= ind_u)\n",
        "  Dists *= Mask\n",
        "\n",
        "  return Dists\n",
        "\n",
        "\n",
        "# @jit(nopython=True)\n",
        "# def db2rain(image):\n",
        "#   image = image**2 - 1\n",
        "#   image[image<0] = 0\n",
        "\n",
        "#   return image\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def db2rain(image):\n",
        "  image = 10 * image**2 - 0.5*np.random.rand(1)\n",
        "  # image[image<0] = 0\n",
        "  image = np.maximum(image, 0)\n",
        "  return image\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def create_pairs(image, n_pairs = 1):\n",
        "  distx = np.random.randint(0,32, (n_pairs,))\n",
        "  disty = np.random.randint(-15, 16, (n_pairs,))\n",
        "\n",
        "  perceived_image = db2rain(image)\n",
        "  trace =  np.zeros(image.shape)\n",
        "  pairs = []\n",
        "  for i in range(n_pairs):\n",
        "\n",
        "    coli0 = np.random.randint(0, 64 - distx[i], (1,)).item()\n",
        "    rowi0 = np.random.randint(max(0, 0 - disty[i]), min(64, 64 - disty[i]), (1,)).item()\n",
        "    coli1 = coli0 + distx[i]\n",
        "    rowi1 = rowi0 + disty[i]\n",
        "    xi0_local = np.random.rand(1).item()\n",
        "    xi1_local = (distx[i] + np.random.rand(1)).item()\n",
        "\n",
        "    xi0_global = coli0 + xi0_local\n",
        "    xi1_global = coli0 + xi1_local\n",
        "\n",
        "    if rowi1 > rowi0:\n",
        "        rowi_max = rowi1\n",
        "        rowi_min = rowi0\n",
        "        yi0_local = rowi1 - rowi0 + np.random.rand(1).item()\n",
        "        yi1_local =  np.random.rand(1).item()\n",
        "        yi0_global = 64 - rowi1 + yi0_local\n",
        "        yi1_global = 64 - rowi1 + yi1_local\n",
        "\n",
        "    else :\n",
        "        rowi_max = rowi0\n",
        "        rowi_min = rowi1\n",
        "        yi1_local = rowi0 - rowi1 + np.random.rand(1).item()\n",
        "        yi0_local =  np.random.rand(1).item()\n",
        "        yi0_global = 64 - rowi0 + yi0_local\n",
        "        yi1_global = 64 - rowi0 + yi1_local\n",
        "\n",
        "\n",
        "\n",
        "    cropi = perceived_image[0, rowi_min:rowi_max+1, coli0:coli1+1]\n",
        "    # print((xi0_local, yi0_local), (xi1_local, yi1_local), cropi.shape)\n",
        "    distsi = get_dists((xi0_local, yi0_local), (xi1_local, yi1_local), cropi)\n",
        "    meani = np.sum(distsi * cropi) / np.sum(distsi)\n",
        "    trace[0, rowi_min:rowi_max+1, coli0:coli1+1] += (0.2 + meani) * (distsi > 0)\n",
        "    pairs.append(((xi0_global, yi0_global), (xi1_global, yi1_global), meani))\n",
        "\n",
        "  return perceived_image, trace, pairs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_image(image, lambda_pairs=0.01, lambda_rec=0.001,\n",
        "                             lambda_noisy_rec=0.001, lambda_disc=0.001,\n",
        "                             lambda_square=0., pola=[0,0.5,0.1]):\n",
        "\n",
        "    clean_image = image\n",
        "    for k in range(np.random.poisson(lambda_disc*64*64)):\n",
        "        r = randint(5,10)\n",
        "        clean_image=simu_disc(image, lambda a,x  : (0.39 - 0.36*a/x**2)*(a < x**2), radius = r)  #0.47 pour avoir 40 dB\n",
        "    for k in range(np.random.poisson(lambda_square*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_square(clean_image, lambda a,x  : (0.5 - 0.45*a/x)*(a < x) , diag = r)  #0.47 pour avoir 40 dB\n",
        "#        print(r)\n",
        "    for i in range(np.random.poisson(lambda_rec*64*64)):\n",
        "        L=randint(20,50)\n",
        "        l=randint(2,10)\n",
        "        image= simu_rec(image,L,l)\n",
        "    for j in range(np.random.poisson(lambda_noisy_rec*64*64)):\n",
        "        L=randint(10,30)\n",
        "        l=randint(10,30)\n",
        "        image = simu_noisy_rec(image,L,l)\n",
        "        # 0.3*np.exp(-0.1 * a/x)*(a < x**2)  #image=simu_disque(image, lambda a,x  : 1.0*(a < x**2)  )\n",
        "    # on ajoute le deuxième canal où les échanges entre signaux seront\n",
        "    # représentés\n",
        "\n",
        "\n",
        "    return clean_image, image\n",
        "\n",
        "def make_image_with_pairs(rec, freq_integrated_signals, noisy_rec ,disc,square, pola, n_pairs):\n",
        "    image=torch.zeros([1,64, 64])\n",
        "    clean_image, noisy_image = generate_image(image, lambda_pairs=freq_integrated_signals,\n",
        "                                     lambda_rec=rec, lambda_noisy_rec=noisy_rec,\n",
        "                                     lambda_disc=disc, lambda_square=square,\n",
        "                                     pola= pola)\n",
        "    ground_clean_image, trace, pairs = create_pairs(clean_image.numpy(), n_pairs)\n",
        "    return noisy_image.unsqueeze(0), torch.tensor(ground_clean_image).unsqueeze(0),  torch.tensor(trace).unsqueeze(0), pairs\n",
        "\n",
        "def make_batch_with_pairs(batch_size, freq_integrated_signals, rec, noisy_rec,\n",
        "                                disc, square=0.001, pola=[0], n_pairs=1):\n",
        "    ground_clean_images = []\n",
        "    noisy_images = []\n",
        "    traces = []\n",
        "    pairs_list = []\n",
        "    for i in range(batch_size):\n",
        "        noisy_image, ground_clean_image, trace, pairs = make_image_with_pairs(rec, freq_integrated_signals,\n",
        "                                                          noisy_rec, disc, square, pola, n_pairs)\n",
        "        ground_clean_images.append(ground_clean_image)\n",
        "        noisy_images.append(noisy_image)\n",
        "        traces.append(trace)\n",
        "        pairs_list.append(pairs)\n",
        "\n",
        "    ground_clean_images=torch.cat(ground_clean_images, dim = 0).float()\n",
        "    noisy_images=torch.cat(noisy_images, dim = 0).float()\n",
        "    traces=torch.cat(traces, dim = 0).float()\n",
        "\n",
        "    return ground_clean_images, noisy_images, traces, pairs_list\n",
        "\n",
        "\n",
        "def extract_random_points(images, M):\n",
        "    \"\"\"\n",
        "    Extract M random values from each image in a batch, along with their normalized coordinates, using PyTorch.\n",
        "\n",
        "    Args:\n",
        "    images (torch.Tensor): Input batch of images of shape (N, 1, S, S).\n",
        "    M (int): Number of random points to extract from each image.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Batch of extracted points and their values, shape (N, M, 3).\n",
        "    \"\"\"\n",
        "    N, _, S, _ = images.shape\n",
        "    # Flatten the spatial dimensions\n",
        "    flat_images = images.view(N, S * S)\n",
        "\n",
        "    # Randomly sample M indices for each image in the batch\n",
        "    indices = torch.randint(0, S * S, (N, M), device=images.device)\n",
        "\n",
        "    # Gather the values from these indices for all images\n",
        "    sampled_values = torch.gather(flat_images, 1, indices)\n",
        "\n",
        "    # Calculate coordinates from indices\n",
        "    rows = indices // S\n",
        "    cols = indices % S\n",
        "\n",
        "    # Normalize coordinates to be between 0 and 1\n",
        "    normalized_rows = rows.float() / S\n",
        "    normalized_cols = cols.float() / S\n",
        "\n",
        "    # Stack the normalized coordinates with the values\n",
        "    result = torch.stack((normalized_rows, normalized_cols, sampled_values.float()), dim=-1)\n",
        "\n",
        "    return result\n",
        "\n",
        "def set_tensor_values(X, extracted_data, S=64):\n",
        "    \"\"\"\n",
        "    Set values in tensor X using coordinates and values extracted from another tensor.\n",
        "\n",
        "    Args:\n",
        "    X (torch.Tensor): Target tensor where values need to be set, shape (N, 1, S, S).\n",
        "    extracted_data (torch.Tensor): Data containing normalized coordinates and values, shape (N, M, 3).\n",
        "    S (int): Size of the spatial dimension of X.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Updated tensor X with new values set at specified coordinates.\n",
        "    \"\"\"\n",
        "    N, M, _ = extracted_data.shape\n",
        "\n",
        "    # Extract normalized coordinates and values\n",
        "    normalized_rows = extracted_data[:, :, 0]\n",
        "    normalized_cols = extracted_data[:, :, 1]\n",
        "    values = extracted_data[:, :, 2]\n",
        "\n",
        "    # Convert normalized coordinates back to original scale\n",
        "    rows = (normalized_rows * S).long()\n",
        "    cols = (normalized_cols * S).long()\n",
        "\n",
        "    # Use the coordinates to set the values in X\n",
        "    for i in range(N):\n",
        "        for j in range(M):\n",
        "            X[i, 0, rows[i, j], cols[i, j]] = values[i, j]\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def pairs_list2pairs_batch(list_of_lists, size = 64.):\n",
        "    \"\"\"\n",
        "    Transform a list of lists containing triplets into a 3D numpy array.\n",
        "\n",
        "    Args:\n",
        "    list_of_lists (list): List of Nb lists, each containing Np triplets as described.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: A 3D numpy array of shape (Nb, Np, 5) as specified.\n",
        "    \"\"\"\n",
        "    # Using list comprehension to transform and flatten each triplet\n",
        "    batch = torch.tensor([\n",
        "        [\n",
        "            [p1[0]/size, p1[1]/size, p2[0]/size, p2[1]/size, val]\n",
        "            for (p1, p2, val) in sublist\n",
        "        ]\n",
        "        for sublist in list_of_lists\n",
        "    ])\n",
        "\n",
        "    return batch\n",
        "\n",
        "def gen_image_with_pairs(batch_size, n_pairs, n_points):\n",
        "    freq_integrated_signals = 0.005\n",
        "    ground_clean_images, noisy_images, traces, pairs_list = make_batch_with_pairs(batch_size, freq_integrated_signals, 0.001, 0, 0.001, square=0., pola=[0], n_pairs=n_pairs)\n",
        "    pairs_list = pairs_list2pairs_batch(pairs_list, size = 64.)\n",
        "    partial_target = extract_random_points(ground_clean_images, n_points)\n",
        "\n",
        "    return ground_clean_images, partial_target, noisy_images, traces.float(), pairs_list\n",
        "\n",
        "#####################################################################################################\n",
        "#################################### Passage PointCloud #############################################\n",
        "\n",
        "def get_random_triplets(tensor, N, M): # N : max non zero elements M: total elements\n",
        "    # Find indices of non-zero elements\n",
        "    non_zero_indices = torch.nonzero(tensor, as_tuple=True)\n",
        "    row_indices, col_indices = non_zero_indices\n",
        "\n",
        "    # Extract corresponding non-zero values\n",
        "    values = tensor[non_zero_indices]\n",
        "\n",
        "    # Create triplets for non-zero elements\n",
        "    non_zero_triplets = torch.stack((row_indices, col_indices, values), dim=1)\n",
        "\n",
        "    # Shuffle the non-zero triplets\n",
        "    shuffle_indices = torch.randperm(non_zero_triplets.size(0))\n",
        "    shuffled_non_zero_triplets = non_zero_triplets[shuffle_indices]\n",
        "\n",
        "    # Determine the number of non-zero triplets\n",
        "    K = shuffled_non_zero_triplets.size(0)\n",
        "\n",
        "    if K > N :\n",
        "      shuffled_non_zero_triplets = shuffled_non_zero_triplets[:N]\n",
        "    # print(shuffled_non_zero_triplets.size(0))\n",
        "    # Find zero values to potentially add\n",
        "    zero_indices = torch.nonzero(tensor == 0, as_tuple=True)\n",
        "    zero_row_indices, zero_col_indices = zero_indices\n",
        "\n",
        "    # Create zero triplets\n",
        "    zero_triplets = torch.stack((zero_row_indices, zero_col_indices, 0 * zero_col_indices), dim=1)\n",
        "\n",
        "    # Shuffle zero triplets\n",
        "    shuffle_indices_zero = torch.randperm(zero_triplets.size(0))\n",
        "    shuffled_zero_triplets = zero_triplets[shuffle_indices_zero]\n",
        "\n",
        "    # Subsample N-K zero triplets\n",
        "    # L = shuffled_zero_triplets.size(0)\n",
        "    subsampled_zero_triplets = shuffled_zero_triplets[:(M - N)]\n",
        "    # print('nnn', subsampled_zero_triplets.size(0))\n",
        "    # Combine non-zero and zero triplets\n",
        "    final_triplets = torch.cat((shuffled_non_zero_triplets, subsampled_zero_triplets), dim=0)\n",
        "\n",
        "\n",
        "    return final_triplets.unsqueeze(dim=0)\n",
        "\n",
        "\n",
        "def get_random_xy_triplets(x, y, N, M): # N : max non zero elements M: total elements\n",
        "    # Find indices of non-zero elements\n",
        "    non_zero_indices = torch.nonzero(x, as_tuple=True)\n",
        "    row_indices, col_indices = non_zero_indices\n",
        "\n",
        "    # Extract corresponding non-zero values\n",
        "    valuesx = x[non_zero_indices]\n",
        "    valuesy = y[non_zero_indices]\n",
        "\n",
        "    # Create triplets for non-zero elements\n",
        "    non_zero_triplets_x = torch.stack((row_indices, col_indices, valuesx), dim=1)\n",
        "    non_zero_triplets_y = torch.stack((row_indices, col_indices, valuesy), dim=1)\n",
        "\n",
        "    # Shuffle the non-zero triplets\n",
        "    shuffle_indices = torch.randperm(non_zero_triplets_x.size(0))\n",
        "    shuffled_non_zero_triplets_x = non_zero_triplets_x[shuffle_indices]\n",
        "    shuffled_non_zero_triplets_y = non_zero_triplets_y[shuffle_indices]\n",
        "\n",
        "    # Determine the number of non-zero triplets\n",
        "    K = shuffled_non_zero_triplets_x.size(0)\n",
        "\n",
        "    if K > N :\n",
        "      shuffled_non_zero_triplets_x = shuffled_non_zero_triplets_x[:N]\n",
        "      shuffled_non_zero_triplets_y = shuffled_non_zero_triplets_y[:N]\n",
        "    K = min(K,N)\n",
        "\n",
        "    # Find zero values to potentially add\n",
        "    zero_indices = torch.nonzero(x == 0, as_tuple=True)\n",
        "    zero_row_indices, zero_col_indices = zero_indices\n",
        "\n",
        "    # Create zero triplets\n",
        "    zero_triplets_x = torch.stack((zero_row_indices, zero_col_indices, 0 * zero_col_indices), dim=1)\n",
        "    zero_triplets_y = torch.stack((zero_row_indices, zero_col_indices, y[zero_indices]), dim=1)\n",
        "\n",
        "    # Shuffle zero triplets\n",
        "    shuffle_indices_zero = torch.randperm(zero_triplets_x.size(0))\n",
        "    shuffled_zero_triplets_x = zero_triplets_x[shuffle_indices_zero]\n",
        "    shuffled_zero_triplets_y = zero_triplets_y[shuffle_indices_zero]\n",
        "\n",
        "    # Subsample N-K zero triplets\n",
        "    # L = shuffled_zero_triplets.size(0)\n",
        "    subsampled_zero_triplets_x = shuffled_zero_triplets_x[:(M - K)]\n",
        "    subsampled_zero_triplets_y = shuffled_zero_triplets_y[:(M - K)]\n",
        "    # print('nnn', subsampled_zero_triplets.size(0))\n",
        "    # Combine non-zero and zero triplets\n",
        "    final_triplets_x = torch.cat((shuffled_non_zero_triplets_x, subsampled_zero_triplets_x), dim=0)\n",
        "    final_triplets_y = torch.cat((shuffled_non_zero_triplets_y, subsampled_zero_triplets_y), dim=0)\n",
        "\n",
        "    return final_triplets_x, final_triplets_y\n"
      ],
      "metadata": {
        "id": "Vle-V9-T_HwB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randint\n",
        "randint(0, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPVuR810K4rf",
        "outputId": "5849b3b0-ba00-44ee-9b9a-18cd02ff0c90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randint\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def simu_rec(image, L,l,  fields=0):\n",
        "    channels,size,size2=image.size()\n",
        "    rec= torch.zeros(channels,size,size2)\n",
        "    #out = 0*(image.clone())\n",
        "    vertical=np.random.binomial(1,0.5)==1\n",
        "    if vertical:\n",
        "        width=l\n",
        "        height=L\n",
        "    else:\n",
        "        width=L\n",
        "        height=l\n",
        "\n",
        "    top=randint(0, size-height)\n",
        "    left=randint(0, size-width)\n",
        "    rec[fields,top:top+height,left:left+width]=  np.random.uniform(0,0.4)   #0.1\n",
        "    image=image + rec\n",
        "    return image\n",
        "\n",
        "def simu_noisy_rec(image, L,l,  fields=0):\n",
        "    channels,size,size2=image.size()\n",
        "    rec= torch.zeros(channels,size,size2)\n",
        "    #out = 0*(image.clone())\n",
        "    vertical=np.random.binomial(1,0.5)==1\n",
        "    if vertical:\n",
        "        width=l\n",
        "        height=L\n",
        "    else:\n",
        "        width=L\n",
        "        height=l\n",
        "\n",
        "    top=randint(0, size-height)\n",
        "    left=randint(0, size-width)\n",
        "    rec[fields,top:top+height,left:left+width]= np.random.uniform(0,0.4)  #0.1\n",
        "    noise=torch.randn(channels,size,size2)\n",
        "    noise=noise*(noise>0).float()\n",
        "    rec=noise*rec\n",
        "    image=image + rec\n",
        "    return image\n",
        "\n",
        "def simu_disc(image, f, radius=15, fields=0 ):  #radial decrease function  #or 12\n",
        "    channels,size,size2=image.size()\n",
        "    center=np.array([randint(radius, size-radius) , randint(radius, size-radius) ])\n",
        "    npdisc= f( ((np.arange(0,64)*np.ones([size,size])) - center[0])**2 + (np.transpose(np.arange(0,64)*np.ones([size,size]))-center[1])**2  , radius)\n",
        "    npdisc=np.random.uniform(0.6,1.) * npdisc  #variation on intensity\n",
        "    image[fields,:,:] = image[fields,:,:] + torch.from_numpy(npdisc).float()   #matrice des distances < rayon\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def simu_moving_disc(image):\n",
        "  nsteps, size, _ = image.shape\n",
        "\n",
        "  # Initialize centers and radii arrays\n",
        "  centers = np.zeros((nsteps, 2))\n",
        "  radii = np.zeros(nsteps)\n",
        "\n",
        "  # Choose k\n",
        "  k = np.random.randint(0,size)\n",
        "\n",
        "  # Generate the kth center and radius\n",
        "  radius_k = np.abs(np.random.normal(10, 8))\n",
        "  center_k = radius_k + (size - radius_k) * np.random.random(2)\n",
        "\n",
        "  # Generate advection speed and radius increment\n",
        "  advection_speed = np.random.normal(0, 3, 2)\n",
        "  radius_increment = np.random.normal(0, 8/nsteps)\n",
        "\n",
        "\n",
        "\n",
        "  # Fill centers and radii arrays\n",
        "\n",
        "  abs_centers = center_k[0] + (np.arange(nsteps) - k) * advection_speed[0]\n",
        "  ord_centers = center_k[1] + (np.arange(nsteps) - k) * advection_speed[1]\n",
        "  radii = radius_k  +  (np.arange(nsteps) - k) * radius_increment\n",
        "  radii[radii <= 0] = 0\n",
        "\n",
        "  np.arange(0,size)*np.ones([1, size,size])\n",
        "  distances_to_centers = (np.arange(0,size)*np.ones([1, size,size]) - abs_centers.reshape((nsteps, 1, 1)))**2 + \\\n",
        "    (np.transpose(np.arange(0,size)*np.ones([size,size])) - ord_centers.reshape((nsteps, 1, 1)))**2\n",
        "\n",
        "  discs =  1. * (distances_to_centers < radii.reshape(nsteps, 1, 1)**2)\n",
        "  # discs =  (0.39 - 0.36*distance_to_centers/radii**2)*(distances_to_centers < radii**2)\n",
        "\n",
        "  # apply a random intensity\n",
        "  discs *= np.random.uniform(0.1,1.)\n",
        "  image = image + discs\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "def generate_noise(image, lambda_rec=0.001 ,lambda_noisy_rec = 0.001, lambda_disc = 0.001, lambda_square = 0., pola=[0,0.5,0.1]):\n",
        "    for k in range(np.random.poisson(lambda_disc*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_disc(image, lambda a,x  : (0.39 - 0.36*a/x**2)*(a < x**2) ,radius = r)  #0.47 pour avoir 40 dB\n",
        "    for k in range(np.random.poisson(lambda_square*64*64)):\n",
        "        r = randint(5,10)\n",
        "        image=simu_square(image, lambda a,x  : (0.5 - 0.45*a/x)*(a < x) , diag = r)  #0.47 pour avoir 40 dB\n",
        "#        print(r)\n",
        "\n",
        "    for i in range(np.random.poisson(lambda_rec*64*64)):\n",
        "        L=randint(20,50)\n",
        "        l=randint(2,10)\n",
        "        image= simu_rec(image,L,l)\n",
        "    for j in range(np.random.poisson(lambda_noisy_rec*64*64)):\n",
        "        L=randint(10,30)\n",
        "        l=randint(10,30)\n",
        "        image= simu_noisy_rec(image,L,l)\n",
        "        # 0.3*np.exp(-0.1 * a/x)*(a < x**2)  #image=simu_disque(image, lambda a,x  : 1.0*(a < x**2)  )\n",
        "    if pola[0]==1:      #add a pseudo pola field\n",
        "        image_pola = generate_pola(image,pola)\n",
        "        image=torch.cat([image,image_pola],dim=0)\n",
        "    return image\n",
        "\n",
        "\n",
        "def make_image_with_pairs(rec, freq_integrated_signals, noisy_rec ,disc,square=0., pola=[0]):\n",
        "    image=torch.zeros([nsteps, 64, 64])\n",
        "    image = generate_noise_and_pairs(image, lambda_pairs=freq_integrated_signals,\n",
        "                                     lambda_rec=rec, lambda_noisy_rec=noisy_rec,\n",
        "                                     lambda_disc=disc, lambda_square=square,\n",
        "                                     pola= pola)\n",
        "    return image\n",
        "\n",
        "\n",
        "def plot_images(images):\n",
        "    # Assuming 'images' is a numpy array of shape (60, 64, 64)\n",
        "    fig, axs = plt.subplots(nrows=6, ncols=10, figsize=(20, 12))  # Adjust figsize to suit your needs\n",
        "    axs = axs.flatten()  # Flatten the 2D array of axes to 1D for easy iteration\n",
        "\n",
        "    for i, ax in enumerate(axs):\n",
        "        # Normalize the image to [0, 1] scale\n",
        "        # img_normalized = (images[i] - np.min(images[i])) / (np.max(images[i]) - np.min(images[i]))\n",
        "\n",
        "        # Display the image\n",
        "        ax.imshow(images[i], cmap='gray', aspect='auto')  # 'gray' colormap and 'auto' aspect ratio\n",
        "        ax.axis('off')  # Hide axes\n",
        "\n",
        "    plt.tight_layout()  # Adjust subplots to give some padding between images\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dtyiAhAm_K6b"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(0,size)*np.ones([1, size, size])"
      ],
      "metadata": {
        "id": "_WkY9oZyo85d",
        "outputId": "3d7e913c-dcdd-4e40-ad3e-12bde228b3ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.,  1.,  2., ..., 61., 62., 63.],\n",
              "        [ 0.,  1.,  2., ..., 61., 62., 63.],\n",
              "        [ 0.,  1.,  2., ..., 61., 62., 63.],\n",
              "        ...,\n",
              "        [ 0.,  1.,  2., ..., 61., 62., 63.],\n",
              "        [ 0.,  1.,  2., ..., 61., 62., 63.],\n",
              "        [ 0.,  1.,  2., ..., 61., 62., 63.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "nsteps = 60\n",
        "image=np.zeros((nsteps, 64, 64))\n",
        "image = simu_moving_disc(image)\n",
        "plot_images(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_ANkUnaJ9M3Z",
        "outputId": "be44763a-75d9-4f41-a611-4131ab44a404"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypingError",
          "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nNo implementation of function Function(<function ones at 0x7ec8e1f805e0>) found for signature:\n \n >>> ones(list(int64)<iv=None>)\n \nThere are 2 candidate implementations:\n      - Of which 2 did not match due to:\n      Overload in function 'ol_np_ones': File: numba/np/arrayobj.py: Line 4501.\n        With argument(s): '(list(int64)<iv=None>)':\n       Rejected as the implementation raised a specific error:\n         TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n       No implementation of function Function(<built-in function empty>) found for signature:\n        \n        >>> empty(list(int64)<iv=None>, dtype=none)\n        \n       There are 2 candidate implementations:\n             - Of which 2 did not match due to:\n             Overload in function 'ol_np_empty': File: numba/np/arrayobj.py: Line 4355.\n               With argument(s): '(list(int64)<iv=None>, dtype=none)':\n              Rejected as the implementation raised a specific error:\n                TypingError: Cannot parse input types to function np.empty(list(int64)<iv=None>, none)\n         raised from /usr/local/lib/python3.10/dist-packages/numba/np/arrayobj.py:4374\n       \n       During: resolving callee type: Function(<built-in function empty>)\n       During: typing of call at /usr/local/lib/python3.10/dist-packages/numba/np/arrayobj.py (4508)\n       \n       \n       File \"../usr/local/lib/python3.10/dist-packages/numba/np/arrayobj.py\", line 4508:\n           def impl(shape, dtype=None):\n               arr = np.empty(shape, dtype=dtype)\n               ^\n\n  raised from /usr/local/lib/python3.10/dist-packages/numba/core/typeinfer.py:1086\n\nDuring: resolving callee type: Function(<function ones at 0x7ec8e1f805e0>)\nDuring: typing of call at <ipython-input-62-42fc682235e2> (82)\n\n\nFile \"<ipython-input-62-42fc682235e2>\", line 82:\ndef simu_moving_disc(image):  \n    <source elided>\n\n  np.arange(0,size)*np.ones([1, size,size])\n  ^\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-5c64cb5a0174>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnsteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimu_moving_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nNo implementation of function Function(<function ones at 0x7ec8e1f805e0>) found for signature:\n \n >>> ones(list(int64)<iv=None>)\n \nThere are 2 candidate implementations:\n      - Of which 2 did not match due to:\n      Overload in function 'ol_np_ones': File: numba/np/arrayobj.py: Line 4501.\n        With argument(s): '(list(int64)<iv=None>)':\n       Rejected as the implementation raised a specific error:\n         TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n       No implementation of function Function(<built-in function empty>) found for signature:\n        \n        >>> empty(list(int64)<iv=None>, dtype=none)\n        \n       There are 2 candidate implementations:\n             - Of which 2 did not match due to:\n             Overload in function 'ol_np_empty': File: numba/np/arrayobj.py: Line 4355.\n               With argument(s): '(list(int64)<iv=None>, dtype=none)':\n              Rejected as the implementation raised a specific error:\n                TypingError: Cannot parse input types to function np.empty(list(int64)<iv=None>, none)\n         raised from /usr/local/lib/python3.10/dist-packages/numba/np/arrayobj.py:4374\n       \n       During: resolving callee type: Function(<built-in function empty>)\n       During: typing of call at /usr/local/lib/python3.10/dist-packages/numba/np/arrayobj.py (4508)\n       \n       \n       File \"../usr/local/lib/python3.10/dist-packages/numba/np/arrayobj.py\", line 4508:\n           def impl(shape, dtype=None):\n               arr = np.empty(shape, dtype=dtype)\n               ^\n\n  raised from /usr/local/lib/python3.10/dist-packages/numba/core/typeinfer.py:1086\n\nDuring: resolving callee type: Function(<function ones at 0x7ec8e1f805e0>)\nDuring: typing of call at <ipython-input-62-42fc682235e2> (82)\n\n\nFile \"<ipython-input-62-42fc682235e2>\", line 82:\ndef simu_moving_disc(image):  \n    <source elided>\n\n  np.arange(0,size)*np.ones([1, size,size])\n  ^\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(np.arange(0,size)*np.ones([1, size,size]) - abs_centers.reshape((nsteps, 1, 1))).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbQ2YQ73Bmh_",
        "outputId": "c2411fc4-9b35-4559-b799-6a996d400317"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 64, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notre jeu de données contient:\n",
        "# une cible parfaite (lamedeau)\n",
        "# des triplets \"pluviometres\" :\n",
        "# (lon_pluvio, lat_pluvio, taux de pluie mesuré)\n",
        "# des quintuplets \"cmls\" associés aux antennes A & B:\n",
        "# (lon_A, lat_A, lat_B, lon_B, taux de pluie moyen entre A et B)\n",
        "\n",
        "batch_size = 6\n",
        "n_pairs = 16\n",
        "n_points = 16\n",
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "\n",
        "# lame d'eau \"idéale\"\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(lamedeau, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# images radar (bruitées)\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "voir_batch2D(radar, 6, fig2, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Commercial Microwave Links (cmls)\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(cmls_spatialises, 6, fig3, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Superposition Commercial Microwave Links (CMLs), pluviomètres et radar\n",
        "fig4 = plt.figure(4, figsize=(36, 6))\n",
        "cmls_spatialises = set_tensor_values(cmls_spatialises, pluviometres, 64)\n",
        "radar[cmls_spatialises > 0] = cmls_spatialises[cmls_spatialises > 0 ]\n",
        "voir_batch2D(radar, 6, fig4, k=0, min_scale=0., max_scale=1.2)\n"
      ],
      "metadata": {
        "id": "pd1BiavmQnmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
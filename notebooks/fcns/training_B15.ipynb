{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nanopiero/fusion/blob/main/notebooks/fcns/training_B11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1ciEeyNevrd"
   },
   "source": [
    "## B1.5 radar + gauges 1 min + cmls -> gauges 1 min [xrlg1_yg1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7O7I9ZuLLvv"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/nanopiero/fusion.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mdso/lepetitp/ppc/WEBCAMS/src/raincell/ia/notebooks/learning/simulation/fusion/notebooks/fcns\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mU0zdFYCLdgR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('/home/mdso/lepetitp/ppc/WEBCAMS/src/raincell/ia/notebooks/learning/simulation')\n",
    "\n",
    "from fusion.utils.datasets import spatialized_gt, create_cmls_filter, FusionDataset\n",
    "from fusion.utils.datasets import indices_to_sampled_values, get_point_measurements, point_gt, segment_gt, make_noisy_images\n",
    "from torch.utils.data import DataLoader\n",
    "from fusion.utils.fcn import UNet\n",
    "from fusion.utils.cost_functions import QPELoss_fcn, compute_metrics\n",
    "from fusion.utils.viz import set_tensor_values2, plot_images, plot_images_10pts_20seg, plot_results_10pts_20seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gLGZHvSIF5NW"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "P7DnFb_RWwql"
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "num_epochs = 2000\n",
    "save_every = 10\n",
    "path = r'/scratch/mdso/lepetitp/ppc/RAINCELL/models/simulation/checkpoint_fcn_exp_B15_xrlg1_yg1.pt'\n",
    "npairs = 20\n",
    "nsteps = 60\n",
    "ndiscs = 5\n",
    "size_image=64\n",
    "length_dataset = 6400\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# Entraînement\n",
    "npoints = 20\n",
    "dataset = FusionDataset(length_dataset=length_dataset,\n",
    "                        npairs=npairs,\n",
    "                        nsteps=nsteps,\n",
    "                        ndiscs=ndiscs, size_image=size_image)\n",
    "\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "seRZK-_gc-uX"
   },
   "outputs": [],
   "source": [
    "# Tiny UNet V1. 60 new channels for input time series of rain gauges measurements\n",
    "use_fcn = True\n",
    "ch_in = 72 + 60\n",
    "ch_out = nsteps * 3 + 1\n",
    "size = nsteps * 3\n",
    "\n",
    "model = UNet(ch_in, ch_out, size, nb_additional_parameters=16).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = QPELoss_fcn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f4zwoKtaYKRl"
   },
   "outputs": [],
   "source": [
    "# Boucle avec 5 modes d'évaluation\n",
    "val_steps = ['eval_opportunity_cost_spat',\n",
    "             # 'eval_added_value_few_spat',\n",
    "             # 'eval_added_value_half_spat',\n",
    "             'eval_added_value_full_spat',\n",
    "             # 'eval_added_value_full_id',\n",
    "             ]\n",
    "steps = val_steps + ['train']\n",
    "losses = {step:[] for step in steps}\n",
    "last_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(path, \\\n",
    "                            map_location=device)\n",
    "last_epoch = checkpoint['epoch']\n",
    "losses = checkpoint['train_losses']\n",
    "# best_loss = checkpoint['best_loss']\n",
    "model_weights = checkpoint['model']\n",
    "optimizer_state_dict = checkpoint['optimizer']\n",
    "# scheduler_state_dict = checkpoint['scheduler']\n",
    "model.load_state_dict(model_weights)\n",
    "optimizer.load_state_dict(optimizer_state_dict)\n",
    "# scheduler.load_state_dict(scheduler_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEDbRb1iZG6n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n° 1280 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0230, Regression Loss 1h: 319.5636, Segmentation Loss:0.0819\n",
      "Train Confusion Matrix:\n",
      "[[3141964   53963]\n",
      " [  70158  573915]]\n",
      "Accuracy: 0.9677, CSI: 0.8222, Sensitivity: 0.8911, Specificity: 0.9831, False Alarm Ratio: 0.0859\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0207, Regression Loss 1h: 332.1148, Segmentation Loss:0.0756\n",
      "Train Confusion Matrix:\n",
      "[[3145045   50882]\n",
      " [  64745  579328]]\n",
      "Accuracy: 0.9699, CSI: 0.8336, Sensitivity: 0.8995, Specificity: 0.9841, False Alarm Ratio: 0.0807\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0223, Regression Loss 1h: 355.1654, Segmentation Loss:0.0763\n",
      "Train Confusion Matrix:\n",
      "[[1725086   26598]\n",
      " [  37380  315256]]\n",
      "Accuracy: 0.9696, CSI: 0.8313, Sensitivity: 0.8940, Specificity: 0.9848, False Alarm Ratio: 0.0778\n",
      "\n",
      "\n",
      "epoch duration : 113.54589414596558\n",
      "saving step\n",
      "epoch n° 1281 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0232, Regression Loss 1h: 311.7401, Segmentation Loss:0.0836\n",
      "Train Confusion Matrix:\n",
      "[[3152808   53086]\n",
      " [  72924  561182]]\n",
      "Accuracy: 0.9672, CSI: 0.8166, Sensitivity: 0.8850, Specificity: 0.9834, False Alarm Ratio: 0.0864\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0207, Regression Loss 1h: 323.2545, Segmentation Loss:0.0761\n",
      "Train Confusion Matrix:\n",
      "[[3155533   50361]\n",
      " [  65826  568280]]\n",
      "Accuracy: 0.9697, CSI: 0.8303, Sensitivity: 0.8962, Specificity: 0.9843, False Alarm Ratio: 0.0814\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0223, Regression Loss 1h: 342.1594, Segmentation Loss:0.0780\n",
      "Train Confusion Matrix:\n",
      "[[1770513   28403]\n",
      " [  38740  312744]]\n",
      "Accuracy: 0.9688, CSI: 0.8233, Sensitivity: 0.8898, Specificity: 0.9842, False Alarm Ratio: 0.0833\n",
      "\n",
      "\n",
      "epoch duration : 114.25580167770386\n",
      "epoch n° 1282 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0231, Regression Loss 1h: 297.4703, Segmentation Loss:0.0836\n",
      "Train Confusion Matrix:\n",
      "[[3138660   57780]\n",
      " [  68811  574749]]\n",
      "Accuracy: 0.9670, CSI: 0.8195, Sensitivity: 0.8931, Specificity: 0.9819, False Alarm Ratio: 0.0913\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0207, Regression Loss 1h: 301.7477, Segmentation Loss:0.0770\n",
      "Train Confusion Matrix:\n",
      "[[3141905   54535]\n",
      " [  63240  580320]]\n",
      "Accuracy: 0.9693, CSI: 0.8313, Sensitivity: 0.9017, Specificity: 0.9829, False Alarm Ratio: 0.0859\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0214, Regression Loss 1h: 333.9979, Segmentation Loss:0.0766\n",
      "Train Confusion Matrix:\n",
      "[[1749097   27707]\n",
      " [  38085  320151]]\n",
      "Accuracy: 0.9692, CSI: 0.8295, Sensitivity: 0.8937, Specificity: 0.9844, False Alarm Ratio: 0.0797\n",
      "\n",
      "\n",
      "epoch duration : 112.54425859451294\n",
      "epoch n° 1283 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0224, Regression Loss 1h: 320.2814, Segmentation Loss:0.0803\n",
      "Train Confusion Matrix:\n",
      "[[3145740   53557]\n",
      " [  68304  572399]]\n",
      "Accuracy: 0.9683, CSI: 0.8245, Sensitivity: 0.8934, Specificity: 0.9833, False Alarm Ratio: 0.0856\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0202, Regression Loss 1h: 345.1361, Segmentation Loss:0.0736\n",
      "Train Confusion Matrix:\n",
      "[[3150219   49078]\n",
      " [  63627  577076]]\n",
      "Accuracy: 0.9706, CSI: 0.8366, Sensitivity: 0.9007, Specificity: 0.9847, False Alarm Ratio: 0.0784\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0208, Regression Loss 1h: 357.9183, Segmentation Loss:0.0743\n",
      "Train Confusion Matrix:\n",
      "[[1738631   26697]\n",
      " [  36731  317621]]\n",
      "Accuracy: 0.9701, CSI: 0.8335, Sensitivity: 0.8963, Specificity: 0.9849, False Alarm Ratio: 0.0775\n",
      "\n",
      "\n",
      "epoch duration : 113.51803922653198\n",
      "epoch n° 1284 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0231, Regression Loss 1h: 407.2850, Segmentation Loss:0.0813\n",
      "Train Confusion Matrix:\n",
      "[[3137005   52479]\n",
      " [  69948  580568]]\n",
      "Accuracy: 0.9681, CSI: 0.8258, Sensitivity: 0.8925, Specificity: 0.9835, False Alarm Ratio: 0.0829\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0209, Regression Loss 1h: 412.8192, Segmentation Loss:0.0750\n",
      "Train Confusion Matrix:\n",
      "[[3139509   49975]\n",
      " [  64025  586491]]\n",
      "Accuracy: 0.9703, CSI: 0.8373, Sensitivity: 0.9016, Specificity: 0.9843, False Alarm Ratio: 0.0785\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0219, Regression Loss 1h: 400.9106, Segmentation Loss:0.0755\n",
      "Train Confusion Matrix:\n",
      "[[1713644   26941]\n",
      " [  36495  315720]]\n",
      "Accuracy: 0.9697, CSI: 0.8327, Sensitivity: 0.8964, Specificity: 0.9845, False Alarm Ratio: 0.0786\n",
      "\n",
      "\n",
      "epoch duration : 113.319828748703\n",
      "epoch n° 1285 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.3822, Regression Loss 1h: 866.4398, Segmentation Loss:0.0973\n",
      "Train Confusion Matrix:\n",
      "[[3144754   52260]\n",
      " [  72060  570926]]\n",
      "Accuracy: 0.9676, CSI: 0.8212, Sensitivity: 0.8879, Specificity: 0.9837, False Alarm Ratio: 0.0839\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.2691, Regression Loss 1h: 841.9381, Segmentation Loss:0.0853\n",
      "Train Confusion Matrix:\n",
      "[[3147695   49319]\n",
      " [  65603  577383]]\n",
      "Accuracy: 0.9701, CSI: 0.8340, Sensitivity: 0.8980, Specificity: 0.9846, False Alarm Ratio: 0.0787\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0218, Regression Loss 1h: 372.4981, Segmentation Loss:0.0765\n",
      "Train Confusion Matrix:\n",
      "[[1679415   26117]\n",
      " [  36561  304627]]\n",
      "Accuracy: 0.9694, CSI: 0.8294, Sensitivity: 0.8928, Specificity: 0.9847, False Alarm Ratio: 0.0790\n",
      "\n",
      "\n",
      "epoch duration : 115.57431411743164\n",
      "epoch n° 1286 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0229, Regression Loss 1h: 315.3449, Segmentation Loss:0.0831\n",
      "Train Confusion Matrix:\n",
      "[[3137539   53965]\n",
      " [  71168  577328]]\n",
      "Accuracy: 0.9674, CSI: 0.8219, Sensitivity: 0.8903, Specificity: 0.9831, False Alarm Ratio: 0.0855\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0205, Regression Loss 1h: 315.4592, Segmentation Loss:0.0762\n",
      "Train Confusion Matrix:\n",
      "[[3140588   50916]\n",
      " [  65153  583343]]\n",
      "Accuracy: 0.9698, CSI: 0.8340, Sensitivity: 0.8995, Specificity: 0.9840, False Alarm Ratio: 0.0803\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0221, Regression Loss 1h: 323.6526, Segmentation Loss:0.0762\n",
      "Train Confusion Matrix:\n",
      "[[1678290   26327]\n",
      " [  36339  305764]]\n",
      "Accuracy: 0.9694, CSI: 0.8299, Sensitivity: 0.8938, Specificity: 0.9846, False Alarm Ratio: 0.0793\n",
      "\n",
      "\n",
      "epoch duration : 113.66496253013611\n",
      "epoch n° 1287 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0232, Regression Loss 1h: 314.2791, Segmentation Loss:0.0813\n",
      "Train Confusion Matrix:\n",
      "[[3148599   54490]\n",
      " [  67947  568964]]\n",
      "Accuracy: 0.9681, CSI: 0.8229, Sensitivity: 0.8933, Specificity: 0.9830, False Alarm Ratio: 0.0874\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0209, Regression Loss 1h: 322.9479, Segmentation Loss:0.0749\n",
      "Train Confusion Matrix:\n",
      "[[3152418   50671]\n",
      " [  63498  573413]]\n",
      "Accuracy: 0.9703, CSI: 0.8340, Sensitivity: 0.9003, Specificity: 0.9842, False Alarm Ratio: 0.0812\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0216, Regression Loss 1h: 333.0325, Segmentation Loss:0.0755\n",
      "Train Confusion Matrix:\n",
      "[[1786792   27563]\n",
      " [  38618  320467]]\n",
      "Accuracy: 0.9696, CSI: 0.8288, Sensitivity: 0.8925, Specificity: 0.9848, False Alarm Ratio: 0.0792\n",
      "\n",
      "\n",
      "epoch duration : 112.29770541191101\n",
      "epoch n° 1288 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0234, Regression Loss 1h: 320.4199, Segmentation Loss:0.0810\n",
      "Train Confusion Matrix:\n",
      "[[3142955   54427]\n",
      " [  68207  574411]]\n",
      "Accuracy: 0.9681, CSI: 0.8241, Sensitivity: 0.8939, Specificity: 0.9830, False Alarm Ratio: 0.0866\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0209, Regression Loss 1h: 331.0977, Segmentation Loss:0.0745\n",
      "Train Confusion Matrix:\n",
      "[[3146798   50584]\n",
      " [  63281  579337]]\n",
      "Accuracy: 0.9703, CSI: 0.8357, Sensitivity: 0.9015, Specificity: 0.9842, False Alarm Ratio: 0.0803\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0219, Regression Loss 1h: 331.6103, Segmentation Loss:0.0759\n",
      "Train Confusion Matrix:\n",
      "[[1756238   27612]\n",
      " [  36683  318347]]\n",
      "Accuracy: 0.9699, CSI: 0.8320, Sensitivity: 0.8967, Specificity: 0.9845, False Alarm Ratio: 0.0798\n",
      "\n",
      "\n",
      "epoch duration : 114.57666492462158\n",
      "epoch n° 1289 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0238, Regression Loss 1h: 333.6858, Segmentation Loss:0.0867\n",
      "Train Confusion Matrix:\n",
      "[[3137190   57777]\n",
      " [  72379  572654]]\n",
      "Accuracy: 0.9661, CSI: 0.8148, Sensitivity: 0.8878, Specificity: 0.9819, False Alarm Ratio: 0.0916\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0215, Regression Loss 1h: 303.7294, Segmentation Loss:0.0806\n",
      "Train Confusion Matrix:\n",
      "[[3138978   55989]\n",
      " [  66278  578755]]\n",
      "Accuracy: 0.9682, CSI: 0.8256, Sensitivity: 0.8972, Specificity: 0.9825, False Alarm Ratio: 0.0882\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0224, Regression Loss 1h: 341.1075, Segmentation Loss:0.0803\n",
      "Train Confusion Matrix:\n",
      "[[1819824   29729]\n",
      " [  40213  329754]]\n",
      "Accuracy: 0.9685, CSI: 0.8250, Sensitivity: 0.8913, Specificity: 0.9839, False Alarm Ratio: 0.0827\n",
      "\n",
      "\n",
      "epoch duration : 113.97997689247131\n",
      "epoch n° 1290 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0229, Regression Loss 1h: 348.8106, Segmentation Loss:0.0834\n",
      "Train Confusion Matrix:\n",
      "[[3154800   54280]\n",
      " [  71365  559555]]\n",
      "Accuracy: 0.9673, CSI: 0.8166, Sensitivity: 0.8869, Specificity: 0.9831, False Alarm Ratio: 0.0884\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0206, Regression Loss 1h: 324.3916, Segmentation Loss:0.0772\n",
      "Train Confusion Matrix:\n",
      "[[3158307   50773]\n",
      " [  66597  564323]]\n",
      "Accuracy: 0.9694, CSI: 0.8278, Sensitivity: 0.8944, Specificity: 0.9842, False Alarm Ratio: 0.0825\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0220, Regression Loss 1h: 343.3577, Segmentation Loss:0.0783\n",
      "Train Confusion Matrix:\n",
      "[[1778316   28161]\n",
      " [  39244  316199]]\n",
      "Accuracy: 0.9688, CSI: 0.8243, Sensitivity: 0.8896, Specificity: 0.9844, False Alarm Ratio: 0.0818\n",
      "\n",
      "\n",
      "epoch duration : 114.26540517807007\n",
      "saving step\n",
      "epoch n° 1291 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0274, Regression Loss 1h: 762.0944, Segmentation Loss:0.0841\n",
      "Train Confusion Matrix:\n",
      "[[3143291   54714]\n",
      " [  70882  571113]]\n",
      "Accuracy: 0.9673, CSI: 0.8197, Sensitivity: 0.8896, Specificity: 0.9829, False Alarm Ratio: 0.0874\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0227, Regression Loss 1h: 573.1942, Segmentation Loss:0.0777\n",
      "Train Confusion Matrix:\n",
      "[[3145970   52035]\n",
      " [  65841  576154]]\n",
      "Accuracy: 0.9693, CSI: 0.8302, Sensitivity: 0.8974, Specificity: 0.9837, False Alarm Ratio: 0.0828\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0225, Regression Loss 1h: 410.9929, Segmentation Loss:0.0771\n",
      "Train Confusion Matrix:\n",
      "[[1647306   25561]\n",
      " [  36191  299262]]\n",
      "Accuracy: 0.9693, CSI: 0.8289, Sensitivity: 0.8921, Specificity: 0.9847, False Alarm Ratio: 0.0787\n",
      "\n",
      "\n",
      "epoch duration : 112.9198625087738\n",
      "epoch n° 1292 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0235, Regression Loss 1h: 392.2917, Segmentation Loss:0.0825\n",
      "Train Confusion Matrix:\n",
      "[[3141501   55489]\n",
      " [  68996  574014]]\n",
      "Accuracy: 0.9676, CSI: 0.8218, Sensitivity: 0.8927, Specificity: 0.9826, False Alarm Ratio: 0.0881\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0209, Regression Loss 1h: 349.7247, Segmentation Loss:0.0759\n",
      "Train Confusion Matrix:\n",
      "[[3145072   51918]\n",
      " [  63584  579426]]\n",
      "Accuracy: 0.9699, CSI: 0.8338, Sensitivity: 0.9011, Specificity: 0.9838, False Alarm Ratio: 0.0822\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0222, Regression Loss 1h: 411.5130, Segmentation Loss:0.0746\n",
      "Train Confusion Matrix:\n",
      "[[1811780   28002]\n",
      " [  38553  333505]]\n",
      "Accuracy: 0.9699, CSI: 0.8336, Sensitivity: 0.8964, Specificity: 0.9848, False Alarm Ratio: 0.0775\n",
      "\n",
      "\n",
      "epoch duration : 113.75648856163025\n",
      "epoch n° 1293 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0234, Regression Loss 1h: 394.0746, Segmentation Loss:0.0857\n",
      "Train Confusion Matrix:\n",
      "[[3147496   54870]\n",
      " [  73460  564174]]\n",
      "Accuracy: 0.9666, CSI: 0.8147, Sensitivity: 0.8848, Specificity: 0.9829, False Alarm Ratio: 0.0886\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0210, Regression Loss 1h: 423.5050, Segmentation Loss:0.0786\n",
      "Train Confusion Matrix:\n",
      "[[3151241   51125]\n",
      " [  68040  569594]]\n",
      "Accuracy: 0.9690, CSI: 0.8270, Sensitivity: 0.8933, Specificity: 0.9840, False Alarm Ratio: 0.0824\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0223, Regression Loss 1h: 345.9203, Segmentation Loss:0.0797\n",
      "Train Confusion Matrix:\n",
      "[[1691706   26608]\n",
      " [  38118  301808]]\n",
      "Accuracy: 0.9686, CSI: 0.8234, Sensitivity: 0.8879, Specificity: 0.9845, False Alarm Ratio: 0.0810\n",
      "\n",
      "\n",
      "epoch duration : 114.68362617492676\n",
      "epoch n° 1294 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0230, Regression Loss 1h: 341.2388, Segmentation Loss:0.0835\n",
      "Train Confusion Matrix:\n",
      "[[3129972   55359]\n",
      " [  70350  584319]]\n",
      "Accuracy: 0.9673, CSI: 0.8230, Sensitivity: 0.8925, Specificity: 0.9826, False Alarm Ratio: 0.0865\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0206, Regression Loss 1h: 336.0458, Segmentation Loss:0.0768\n",
      "Train Confusion Matrix:\n",
      "[[3132471   52860]\n",
      " [  63812  590857]]\n",
      "Accuracy: 0.9696, CSI: 0.8351, Sensitivity: 0.9025, Specificity: 0.9834, False Alarm Ratio: 0.0821\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0216, Regression Loss 1h: 344.3435, Segmentation Loss:0.0777\n",
      "Train Confusion Matrix:\n",
      "[[1760423   28254]\n",
      " [  38590  330813]]\n",
      "Accuracy: 0.9690, CSI: 0.8319, Sensitivity: 0.8955, Specificity: 0.9842, False Alarm Ratio: 0.0787\n",
      "\n",
      "\n",
      "epoch duration : 113.24503302574158\n",
      "epoch n° 1295 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0229, Regression Loss 1h: 350.4081, Segmentation Loss:0.0835\n",
      "Train Confusion Matrix:\n",
      "[[3134032   56538]\n",
      " [  69593  579837]]\n",
      "Accuracy: 0.9672, CSI: 0.8213, Sensitivity: 0.8928, Specificity: 0.9823, False Alarm Ratio: 0.0888\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0206, Regression Loss 1h: 361.2651, Segmentation Loss:0.0768\n",
      "Train Confusion Matrix:\n",
      "[[3139241   51329]\n",
      " [  65658  583772]]\n",
      "Accuracy: 0.9695, CSI: 0.8331, Sensitivity: 0.8989, Specificity: 0.9839, False Alarm Ratio: 0.0808\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0220, Regression Loss 1h: 337.5659, Segmentation Loss:0.0765\n",
      "Train Confusion Matrix:\n",
      "[[1741577   27504]\n",
      " [  37777  320502]]\n",
      "Accuracy: 0.9693, CSI: 0.8308, Sensitivity: 0.8946, Specificity: 0.9845, False Alarm Ratio: 0.0790\n",
      "\n",
      "\n",
      "epoch duration : 113.52852320671082\n",
      "epoch n° 1296 \n",
      "\n",
      "eval_opportunity_cost_spat, Regression Loss: 0.0225, Regression Loss 1h: 318.6236, Segmentation Loss:0.0821\n",
      "Train Confusion Matrix:\n",
      "[[3144510   54710]\n",
      " [  68925  571855]]\n",
      "Accuracy: 0.9678, CSI: 0.8222, Sensitivity: 0.8924, Specificity: 0.9829, False Alarm Ratio: 0.0873\n",
      "\n",
      "\n",
      "eval_added_value_full_spat, Regression Loss: 0.0202, Regression Loss 1h: 337.1424, Segmentation Loss:0.0753\n",
      "Train Confusion Matrix:\n",
      "[[3149072   50148]\n",
      " [  64723  576057]]\n",
      "Accuracy: 0.9701, CSI: 0.8337, Sensitivity: 0.8990, Specificity: 0.9843, False Alarm Ratio: 0.0801\n",
      "\n",
      "\n",
      "train, Regression Loss: 0.0213, Regression Loss 1h: 336.6616, Segmentation Loss:0.0771\n",
      "Train Confusion Matrix:\n",
      "[[1767335   27182]\n",
      " [  39073  320650]]\n",
      "Accuracy: 0.9692, CSI: 0.8288, Sensitivity: 0.8914, Specificity: 0.9849, False Alarm Ratio: 0.0781\n",
      "\n",
      "\n",
      "epoch duration : 114.28859996795654\n",
      "epoch n° 1297 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(last_epoch, num_epochs + 1):\n",
    "  t = time.time()\n",
    "  print('epoch n°', epoch, '\\n')\n",
    "\n",
    "  running_regression_loss = {step:0.0 for step in steps}\n",
    "  running_regression_loss_1h = {step:0.0 for step in steps}\n",
    "  running_segmentation_loss = {step:0.0 for step in steps}\n",
    "  running_confusion_matrix = {step: np.zeros((2, 2), dtype=int) for step in steps}\n",
    "\n",
    "  for i, (images, pairs, filters) in enumerate(loader):\n",
    "\n",
    "    # ground truth (not usable)\n",
    "    images = images.clone().detach().float().to(device)\n",
    "\n",
    "    # pseudo radar\n",
    "    noisy_images = make_noisy_images(images)\n",
    "\n",
    "    # pseudo CMLs\n",
    "    pairs = pairs.clone().detach().float().to(device)\n",
    "    filters = filters.clone().float().detach().to(device)\n",
    "\n",
    "    # segment_measurements = segment_gt(images, pairs, filters)\n",
    "    _, segment_measurements_fcn = segment_gt(images, pairs, filters,\n",
    "                                             use_fcn=use_fcn)\n",
    "\n",
    "    #Validation steps\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # splitting\n",
    "      ng_val_inputs_few = 1\n",
    "      ng_val_inputs_half = npoints//4  # 5\n",
    "      ng_val_inputs_comp = npoints//2 - ng_val_inputs_half - ng_val_inputs_few  # 4\n",
    "      ng_val_targets = npoints//2 # 10\n",
    "\n",
    "      # val split\n",
    "      split_val = [ng_val_inputs_few, ng_val_inputs_half, ng_val_inputs_comp, ng_val_targets]\n",
    "      split_few, split_half, split_comp, split_targets = point_gt(images, npoints=npoints,\n",
    "                                                                    use_fcn=use_fcn,\n",
    "                                                                    split=split_val)\n",
    "      _, point_measurements_fcn_eval_few, _ = split_few\n",
    "      _, point_measurements_fcn_eval_half, _ = split_half\n",
    "      _, point_measurements_fcn_eval_comp, _ = split_comp\n",
    "      _, point_measurements_fcn_val_targets, _ = split_targets\n",
    "\n",
    "      # 4 first val steps (10 last pluvios for testing generalization)\n",
    "      targets = point_measurements_fcn_val_targets\n",
    "\n",
    "      # val step 1 : eval_opportunity_cost_spat\n",
    "      step = 'eval_opportunity_cost_spat'\n",
    "      inputs = torch.cat([noisy_images,\n",
    "                          segment_measurements_fcn,\n",
    "                          0 * point_measurements_fcn_eval_few - 0.1\n",
    "                          ], dim=1)\n",
    "      outputs = model(inputs)\n",
    "      regression_loss, regression_loss_1h, segmentation_loss, loss, batch_cm, _ = criterion(model.p, outputs, targets)\n",
    "      running_regression_loss[step] += regression_loss\n",
    "      running_regression_loss_1h[step] += regression_loss_1h\n",
    "      running_segmentation_loss[step] += segmentation_loss\n",
    "      running_confusion_matrix[step] += batch_cm\n",
    "\n",
    "      del inputs, outputs, loss, regression_loss, regression_loss_1h, segmentation_loss\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      # val step 2 : eval_added_value_few_spat\n",
    "      # step = 'eval_added_value_few_spat'\n",
    "      # inputs = torch.cat([noisy_images,\n",
    "      #                     segment_measurements_fcn,\n",
    "      #                     point_measurements_fcn_eval_few\n",
    "      #                     ], dim=1)\n",
    "      # outputs = model(inputs)\n",
    "      # regression_loss, regression_loss_1h, segmentation_loss, loss, batch_cm = criterion(model.p, outputs, targets)\n",
    "      # running_regression_loss[step] += regression_loss\n",
    "      # running_regression_loss_1h[step] += regression_loss_1h\n",
    "      # running_segmentation_loss[step] += segmentation_loss\n",
    "      # running_confusion_matrix[step] += batch_cm\n",
    "\n",
    "      # del inputs, outputs, loss, regression_loss, regression_loss_1h, segmentation_loss\n",
    "      # torch.cuda.empty_cache()\n",
    "\n",
    "      # val step 3 : eval_added_value_half_spat\n",
    "      # step = 'eval_added_value_half_spat'\n",
    "      # inputs = torch.cat([noisy_images,\n",
    "      #                     segment_measurements_fcn,\n",
    "      #                     point_measurements_fcn_eval_half\n",
    "      #                     ], dim=1)\n",
    "      # outputs = model(inputs)\n",
    "      # regression_loss, regression_loss_1h, segmentation_loss, loss, batch_cm = criterion(model.p, outputs, targets)\n",
    "      # running_regression_loss[step] += regression_loss\n",
    "      # running_regression_loss_1h[step] += regression_loss_1h\n",
    "      # running_segmentation_loss[step] += segmentation_loss\n",
    "      # running_confusion_matrix[step] += batch_cm\n",
    "\n",
    "      # del inputs, outputs, loss, regression_loss, regression_loss_1h, segmentation_loss\n",
    "      # torch.cuda.empty_cache()\n",
    "\n",
    "      # val step 4 : eval_added_value_full_spat\n",
    "      step = 'eval_added_value_full_spat'\n",
    "\n",
    "      point_measurements_fcn_eval_full = point_measurements_fcn_eval_few + \\\n",
    "                                          point_measurements_fcn_eval_half + \\\n",
    "                                          point_measurements_fcn_eval_comp\n",
    "\n",
    "      point_measurements_fcn_eval_full += 2 * 0.1 * (point_measurements_fcn_eval_few >= 0)\n",
    "      point_measurements_fcn_eval_full += 2 * 0.1 * (point_measurements_fcn_eval_half >= 0)\n",
    "      point_measurements_fcn_eval_full += 2 * 0.1 * (point_measurements_fcn_eval_comp >= 0)\n",
    "\n",
    "      point_measurements_fcn_eval_full[point_measurements_fcn_eval_full<0] = -0.1\n",
    "\n",
    "      inputs = torch.cat([noisy_images,\n",
    "                          segment_measurements_fcn,\n",
    "                          point_measurements_fcn_eval_full\n",
    "                          ], dim=1)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      regression_loss, regression_loss_1h, segmentation_loss, loss, batch_cm, _ = criterion(model.p, outputs, targets)\n",
    "      running_regression_loss[step] += regression_loss\n",
    "      running_regression_loss_1h[step] += regression_loss_1h\n",
    "      running_segmentation_loss[step] += segmentation_loss\n",
    "      running_confusion_matrix[step] += batch_cm\n",
    "\n",
    "      del inputs, loss, regression_loss, regression_loss_1h, segmentation_loss, split_few, split_half, split_comp, split_targets\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      # last val step, on the 10 first pluvios : eval_added_value_full_id\n",
    "      # step = 'eval_added_value_full_id'\n",
    "      # regression_loss, regression_loss_1h, segmentation_loss, loss, batch_cm = criterion(model.p, outputs, point_measurements_fcn_eval_full) # inputs pluvios serve as targets\n",
    "      # running_regression_loss[step] += regression_loss\n",
    "      # running_regression_loss_1h[step] += regression_loss_1h\n",
    "      # running_segmentation_loss[step] += segmentation_loss\n",
    "      # running_confusion_matrix[step] += batch_cm\n",
    "\n",
    "      # del outputs, loss, regression_loss, regression_loss_1h, segmentation_loss\n",
    "      del point_measurements_fcn_eval_full\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "    # train step\n",
    "    model.train()\n",
    "    step = 'train'\n",
    "    ng_train_inputs = torch.randint(1,9,(1,))\n",
    "    ng_train_targets = npoints // 2 - ng_train_inputs\n",
    "    split_train = [ng_train_inputs, ng_train_targets]\n",
    "\n",
    "\n",
    "    # split  train\n",
    "    split_inputs, split_targets = point_gt(images, npoints=npoints,\n",
    "                                           use_fcn=use_fcn,\n",
    "                                           split=split_train)\n",
    "\n",
    "    _, point_measurements_fcn_train_inputs, _ = split_inputs\n",
    "    _, point_measurements_fcn_train_targets, _ = split_targets\n",
    "\n",
    "    inputs0 = torch.cat([noisy_images,\n",
    "                        segment_measurements_fcn,\n",
    "                        point_measurements_fcn_train_inputs\n",
    "                        ], dim=1)\n",
    "      \n",
    "    inputs1 = torch.cat([noisy_images,\n",
    "                        segment_measurements_fcn,\n",
    "                        point_measurements_fcn_train_targets\n",
    "                        ], dim=1)\n",
    "      \n",
    "    targets0 = point_measurements_fcn_train_targets\n",
    "    targets1 = point_measurements_fcn_train_inputs\n",
    "      \n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    outputs0 = model(inputs0)\n",
    "    outputs1 = model(inputs1)      \n",
    "    regression_loss, regression_loss_1h, segmentation_loss, loss0, batch_cm, _ = criterion(model.p, outputs0, targets0)\n",
    "    _, _, _, loss1, _, _ = criterion(model.p, outputs1, targets1)\n",
    "    loss = loss0 + loss1\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update the weights\n",
    "\n",
    "    running_regression_loss[step] += regression_loss\n",
    "    running_regression_loss_1h[step] += regression_loss_1h\n",
    "    running_segmentation_loss[step] += segmentation_loss\n",
    "    running_confusion_matrix[step] += batch_cm\n",
    "\n",
    "    del split_inputs, inputs0, inputs1, outputs0, outputs1, split_targets, loss0, loss1, loss, regression_loss, regression_loss_1h, segmentation_loss, noisy_images, images, pairs, filters, segment_measurements_fcn\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  if epoch > 0:\n",
    "    for step in steps:\n",
    "      regression_loss = running_regression_loss[step] / len(loader)\n",
    "      regression_loss_1h = running_regression_loss_1h[step] / len(loader)\n",
    "      segmentation_loss = running_segmentation_loss[step] / len(loader)\n",
    "      losses[step].append((epoch, regression_loss, regression_loss_1h, segmentation_loss, running_confusion_matrix[step]))\n",
    "\n",
    "      print(f'{step}, Regression Loss: {regression_loss:.4f}, Regression Loss 1h: {regression_loss_1h:.4f}, Segmentation Loss:{segmentation_loss:.4f}' )\n",
    "      print(\"Train Confusion Matrix:\")\n",
    "      print(running_confusion_matrix[step])\n",
    "      accuracy, csi, sensitivity, specificity, false_alarm_ratio = compute_metrics(running_confusion_matrix[step])\n",
    "      print(f'Accuracy: {accuracy:.4f}, CSI: {csi:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, False Alarm Ratio: {false_alarm_ratio:.4f}')\n",
    "      print('\\n')\n",
    "  print('epoch duration :', time.time() - t)\n",
    "\n",
    "  if (epoch % save_every == 0 or \\\n",
    "    epoch == last_epoch):\n",
    "    print(\"saving step\")\n",
    "    checkpoint = { \n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        # 'scheduler': scheduler.state_dict(),\n",
    "        'train_losses': losses,\n",
    "        }\n",
    "    torch.save(checkpoint, path)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

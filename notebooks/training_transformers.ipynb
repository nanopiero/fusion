{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanopiero/fusion/blob/main/notebooks/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plan d'expérience:\n",
        "\n",
        "Régression\n",
        "\n",
        "      - A.baseline radar cmls -> pluvios\n",
        "\n",
        "Fusion, fusion multitâche\n",
        "\n",
        "    - B.baseline radar + pluvio 1 min + cmls -> pluvios + cmls\n",
        "\n",
        "    - C.tâches aux. 1.  A + tâche aux : -> val cml x masque segment x masque radar + val pluvio x masque pluvio x masque radar\n",
        "\n",
        "    - D. tâches aux 2. tâche reconstruction PPI.\n",
        "      - idée : f(radar[random_sample1], w) = y[70 x 64 x 64].  \n",
        "         ft de coût : ||f(radar[random_sample1])[random_sample1_bar] - target ||\n",
        "         + loss adversariale -> impossibilité de retrouver les indices renseignés\n",
        "\n",
        "    - E. tâche aux 1 + tâche aux 2. A + (B) + c\n",
        "\n",
        "Régression faiblement supervisée\n",
        "\n",
        "    - E. introduction d'un bruit dans les CMLs et les pluvios\n",
        "\n",
        "    - F. correction de l'effet du bruit dans les CMLs dans la loss (weak. sup.)\n",
        "\n",
        "    - G. correction de l'effet du bruit par un réseau auxilaire (// denoising)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie I : régression"
      ],
      "metadata": {
        "id": "JdJDsQ_lMTv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/nanopiero/fusion.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7O7I9ZuLLvv",
        "outputId": "fafb08ef-e9b5-4cfa-badf-f9735c3f6084"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fusion'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 150 (delta 91), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (150/150), 6.60 MiB | 10.14 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mU0zdFYCLdgR"
      },
      "outputs": [],
      "source": [
        "# Imports des bibliothèques utiles\n",
        "# pour l'IA\n",
        "import torch\n",
        "# pour les maths\n",
        "import numpy as np\n",
        "# pour afficher des images et des courbes\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from random import randint\n",
        "import os\n",
        "\n",
        "# imports des fichiers locaux\n",
        "os.chdir('fusion')\n",
        "import utile_fusion\n",
        "# import importlib\n",
        "# importlib.reload(utile_fusion)\n",
        "\n",
        "# Import des fonctions génératrices exploitées à l'échelle de l'image\n",
        "from utile_fusion import spatialized_gt, create_cmls_filter\n",
        "# Import loading tools\n",
        "from utile_fusion import FusionDataset\n",
        "from torch.utils.data import DataLoader\n",
        "# Import des fonctions utilisées à l'échelle du batch, sur carte GPU\n",
        "from utile_fusion import indices_to_sampled_values, get_point_measurements, point_gt, segment_gt, make_noisy_images\n",
        "# Import cost functions\n",
        "from utile_fusion import QPELoss_fcn, compute_metrics\n",
        "# Import des fonctions de visualisation\n",
        "from utile_fusion import set_tensor_values2, plot_images, plot_images_10pts_20seg, plot_results_10pts_20seg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config:\n",
        "npoints = 10\n",
        "npairs = 20\n",
        "nsteps = 60\n",
        "ndiscs = 5\n",
        "size_image=64\n",
        "length_dataset = 6400\n",
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "pVHvI49CbVb8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset, DataLoader\n",
        "dataset = FusionDataset(length_dataset=length_dataset,\n",
        "                        npairs=npairs,\n",
        "                        nsteps=nsteps,\n",
        "                        ndiscs=ndiscs, size_image=size_image)\n",
        "\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=64, num_workers=4)"
      ],
      "metadata": {
        "id": "NNNUcnoEMuSN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Petit UNet\n",
        "from utile_fusion import UNet\n",
        "ch_in = 72\n",
        "ch_out = nsteps * 3\n",
        "size = nsteps * 3\n",
        "\n",
        "model = UNet(ch_in, ch_out, size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "4YvGxXOXubCK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLGZHvSIF5NW",
        "outputId": "028a87bd-98b4-4bd6-c275-7f68b89e3dc5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'/content/drive/MyDrive/rainCell/fusion/models/checkpoint_fcn_08062024.pt'\n",
        "\n",
        "checkpoint = torch.load(path, \\\n",
        "                            map_location=device)\n",
        "last_epoch = checkpoint['epoch']\n",
        "train_losses = checkpoint['train_losses']\n",
        "# best_loss = checkpoint['best_loss']\n",
        "model_weights = checkpoint['model']\n",
        "optimizer_state_dict = checkpoint['optimizer']\n",
        "# scheduler_state_dict = checkpoint['scheduler']\n",
        "# model.load_state_dict(model_weights)\n",
        "# optimizer.load_state_dict(optimizer_state_dict)\n",
        "# scheduler.load_state_dict(scheduler_state_dict)"
      ],
      "metadata": {
        "id": "FTotEeQ6ZMr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = QPELoss_fcn()\n",
        "\n",
        "# Baseline with a FCN\n",
        "use_fcn = True\n",
        "\n",
        "best_loss = [float('inf'), float('inf')]  # Initialize best validation loss to a very high value\n",
        "train_losses = []"
      ],
      "metadata": {
        "id": "CophC2EtlVi6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(100):\n",
        "\n",
        "  running_regression_loss = 0.0\n",
        "  running_segmentation_loss = 0.0\n",
        "  train_confusion_matrix = np.zeros((2, 2), dtype=int)\n",
        "  for i, (images, pairs, filters) in enumerate(loader):\n",
        "\n",
        "    # ground truth (not usable)\n",
        "    images = images.clone().detach().float().to(device)\n",
        "\n",
        "    # pseudo CMLs\n",
        "    pairs = pairs.clone().detach().float().to(device)\n",
        "    filters = filters.clone().float().detach().to(device)\n",
        "\n",
        "    # for transformers :\n",
        "    # segment_measurements = segment_gt(images, pairs, filters)\n",
        "    _, segment_measurements_fcn = segment_gt(images, pairs, filters,\n",
        "                                             use_fcn=use_fcn)\n",
        "\n",
        "    # pseudo pluvios\n",
        "    _, point_measurements_fcn, _ = point_gt(images, npoints=npoints,\n",
        "                                            use_fcn=use_fcn)\n",
        "\n",
        "\n",
        "    # pseudo radar\n",
        "    noisy_images = make_noisy_images(images)\n",
        "\n",
        "    # prepare inputs and targets\n",
        "    inputs = torch.cat([noisy_images, segment_measurements_fcn], dim=1)\n",
        "    targets = point_measurements_fcn\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    outputs = model(inputs)  # Forward pass\n",
        "\n",
        "    regression_loss, segmentation_loss, loss, batch_cm = criterion(model.p, outputs, targets)\n",
        "    loss.backward()  # Backward pass\n",
        "    optimizer.step()  # Update the weights\n",
        "\n",
        "    del inputs, targets, outputs, loss, noisy_images, images, pairs, filters\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    running_regression_loss += regression_loss\n",
        "    running_segmentation_loss += segmentation_loss\n",
        "    train_confusion_matrix += batch_cm\n",
        "\n",
        "  # Calculating average training loss\n",
        "  train_regression_loss = running_regression_loss / len(loader)\n",
        "  train_segmentation_loss = running_segmentation_loss / len(loader)\n",
        "  train_losses.append((epoch, train_regression_loss, train_segmentation_loss, train_confusion_matrix))\n",
        "  print(f'Training, Regression Loss: {train_regression_loss:.4f}, Segmentation Loss:{train_segmentation_loss:.4f}' )\n",
        "  print(\"Train Confusion Matrix:\")\n",
        "  print(train_confusion_matrix)\n",
        "  accuracy, csi, sensitivity, specificity, false_alarm_ratio = compute_metrics(train_confusion_matrix)\n",
        "  print(f'Accuracy: {accuracy:.4f}, CSI: {csi:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, False Alarm Ratio: {false_alarm_ratio:.4f}')\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "id": "Xk3zPTlFWPsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#100 époques : 2h28\n",
        "\n",
        "# checkpoint = {\n",
        "#     'epoch': epoch,\n",
        "#     'model': model.state_dict(),\n",
        "#     'optimizer': optimizer.state_dict(),\n",
        "#     # 'scheduler': scheduler.state_dict(),\n",
        "#     'train_losses': train_losses,\n",
        "#     }\n",
        "# torch.save(checkpoint, path)"
      ],
      "metadata": {
        "id": "LBsQkCXlB2Ae"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = -1\n",
        "j = 1\n",
        "csi_values = [compute_metrics(x[i])[j] for x in train_losses]\n",
        "plt.plot(csi_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "uVP8DMTg0-HR",
        "outputId": "63eca3d3-3d93-47f6-9545-5fd862376508"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e73aee7a0e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tracé output\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  running_regression_loss = 0.0\n",
        "  running_segmentation_loss = 0.0\n",
        "  train_confusion_matrix = np.zeros((2, 2), dtype=int)\n",
        "\n",
        "  for i, (images, pairs, filters) in enumerate(loader):\n",
        "\n",
        "    # ground truth (not usable)\n",
        "    images = images.clone().detach().float().to(device)\n",
        "\n",
        "    # pseudo CMLs\n",
        "    pairs = pairs.clone().detach().float().to(device)\n",
        "    filters = filters.clone().float().detach().to(device)\n",
        "\n",
        "    # generation point and segment measurements\n",
        "    # segment_measurements = segment_gt(images, pairs, filters)\n",
        "    segment_measurements, segment_measurements_fcn = segment_gt(images, pairs, filters, use_fcn=use_fcn)\n",
        "\n",
        "    # pseudo pluvios\n",
        "    point_measurements, point_measurements_fcn, (indices, rows, cols) = \\\n",
        "                        point_gt(images, npoints=npoints, use_fcn=use_fcn)\n",
        "\n",
        "    # pseudo radar\n",
        "    noisy_images = make_noisy_images(images)\n",
        "\n",
        "    # prepare inputs and targets\n",
        "    inputs = torch.cat([noisy_images, segment_measurements_fcn], dim=1)\n",
        "    targets = point_measurements_fcn\n",
        "    outputs = model(inputs)\n",
        "    mask_rnr = outputs[:, :nsteps,...] < outputs[:, nsteps:2*nsteps,...]\n",
        "    images_pred = (mask_rnr * outputs[:, 2*nsteps:3*nsteps, ...]).detach()\n",
        "\n",
        "    # segment_measurements = segment_gt(images, pairs, filters)\n",
        "    segment_measurements_pred, _ = segment_gt(images_pred,\n",
        "                                              pairs,\n",
        "                                              filters,\n",
        "                                              use_fcn=use_fcn)\n",
        "\n",
        "    # pseudo pluvios\n",
        "    sampled_values_pred = indices_to_sampled_values(images_pred, indices)\n",
        "    point_measurements_pred = get_point_measurements(rows, cols,\n",
        "                                                     sampled_values_pred,\n",
        "                                                     size_image)\n",
        "\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LGSWJattoAmz"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "mask_rnr = outputs[:, :nsteps,...] < outputs[:, nsteps:2*nsteps,...]\n",
        "images_pred = (mask_rnr * outputs[:, 2*nsteps:3*nsteps, ...]).detach()\n",
        "k=1\n",
        "plot_images_10pts_20seg(3*images_pred[k,...].cpu().numpy() + filters[k,...].cpu().numpy().sum(axis=0),\n",
        "            noisy_images[k,...].cpu().numpy(),\n",
        "            point_measurements[k,...].cpu().numpy(),\n",
        "            segment_measurements[k,...].cpu().numpy())\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YdcggJIhoAj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "plot_results_10pts_20seg(3*images[k,...].cpu().numpy() + filters[k,...].cpu().numpy().sum(axis=0),\n",
        "                         noisy_images[k,...].cpu().numpy(),\n",
        "                         point_measurements[k,...].cpu().numpy(),\n",
        "                         segment_measurements[k,...].cpu().numpy(),\n",
        "                         3*images_pred[k,...].cpu().numpy() + filters[k,...].cpu().numpy().sum(axis=0),\n",
        "                         (images_pred[k, torch.arange(4, 60, 5), ...] > 0).long().cpu().numpy(),\n",
        "                         point_measurements_pred[k,...].cpu().numpy(), #_pred,\n",
        "                         segment_measurements_pred[k,...].cpu().numpy()) #_pred)"
      ],
      "metadata": {
        "id": "4jbQK-H-Zvx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0LwaOuMZvvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lL-DnpLGZvr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nRmJQB3ZvpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PARXg6M1Zvms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmTxWcUbZvkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6fsUCDmZZvht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxNeyH4oZvfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ib6gVcwAZvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9G1QUnujZvZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AGtZha4VoAej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dnePd4g_oAb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Archi\n",
        "\n",
        "# cas d'un \"fusion transformer 4d\"\n",
        "# Paramètres du modèle :\n",
        "image_size = [64,64]\n",
        "channels = 1\n",
        "patch_size = 4\n",
        "d_model = 120\n",
        "mlp_expansion_ratio = 4\n",
        "d_ff = mlp_expansion_ratio * d_model\n",
        "n_heads = 4\n",
        "n_layers = 12\n",
        "\n",
        "\n",
        "model = FusionTransformer2dplus(image_size, patch_size, n_layers, d_model, d_ff, n_heads, channels=1)\n"
      ],
      "metadata": {
        "id": "4E4h1PR2gpXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install einops\n",
        "\n",
        "#Transformer 2d, time = channels\n",
        "from utile_Transformers import Block, Decoder\n",
        "import torch.nn as nn\n",
        "\n",
        "class UnifiedEmbedding2dplus(nn.Module):\n",
        "  # le temps ici est compté comme un channel\n",
        "    def __init__(self, d_model, patch_size, channels, nsteps):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.patch_size = patch_size\n",
        "        self.channels = channels\n",
        "        self.nsteps = nsteps\n",
        "        self.dim_modality = 4\n",
        "        # Positional embedding for coordinates\n",
        "        self.coord_embed = nn.Linear(2, d_model // 3)\n",
        "\n",
        "        # Modality specific embeddings\n",
        "        self.patch_modality = nn.Parameter(torch.randn(self.dim_modality))\n",
        "        self.point_modality = nn.Parameter(torch.randn(self.dim_modality))\n",
        "        self.segment_modality = nn.Parameter(torch.randn(self.dim_modality))\n",
        "\n",
        "        # Feature embedding for radar image patches\n",
        "        self.patch_feature_embed = nn.Conv2d(channels, d_model - self.dim_modality \\\n",
        "                - 2 * (d_model // 3), kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "        # Feature embedding for point and segment rain rates\n",
        "        self.punctual_rain_rate_embed = nn.Linear(nsteps, d_model - self.dim_modality \\\n",
        "                                                  - 2 * (d_model // 3))\n",
        "        self.integrated_rain_rate_embed = nn.Linear(nsteps, d_model - self.dim_modality \\\n",
        "                                                   - 2 * (d_model // 3))\n",
        "\n",
        "    def forward(self, image, points, segments):\n",
        "        B, C, H, W = image.shape\n",
        "        device = image.device\n",
        "        # print(\"Image shape:\", image.shape)\n",
        "\n",
        "        # Embedding patches\n",
        "        patch_embeddings = self.patch_feature_embed(image).flatten(2).transpose(1, 2)\n",
        "        # print(\"Patch embeddings shape:\", patch_embeddings.shape)\n",
        "\n",
        "        # Create grid for patches\n",
        "        grid_x, grid_y = torch.meshgrid(torch.arange(0, H, self.patch_size), torch.arange(0, W, self.patch_size), indexing='ij')\n",
        "        grid_x = grid_x.to(device)\n",
        "        grid_y = grid_y.to(device)\n",
        "        upleft = torch.stack((grid_x.flatten(), grid_y.flatten()), dim=-1).float()\n",
        "        downright = torch.stack((grid_x.flatten() + self.patch_size, grid_y.flatten() + self.patch_size), dim=-1).float()\n",
        "        # erreur chatGPT !! patch_pos_embeddings = self.coord_embed(upleft) + self.coord_embed(downright)\n",
        "        patch_pos_embeddings = torch.cat([self.coord_embed(upleft), self.coord_embed(downright)], dim=-1)\n",
        "        patch_pos_embeddings = patch_pos_embeddings.repeat(B, 1, 1)\n",
        "        # print(\"Patch positional embeddings shape:\", patch_pos_embeddings.shape)\n",
        "\n",
        "        patch_embeddings = torch.cat([patch_embeddings, patch_pos_embeddings, self.patch_modality.unsqueeze(0).expand(B, patch_embeddings.size(1), -1)], dim=-1)\n",
        "        # print(\"Final patch embeddings shape:\", patch_embeddings.shape)\n",
        "\n",
        "        # Embedding points\n",
        "        point_pos_embeddings = self.coord_embed(points[..., :2].float())\n",
        "        # print(\"Point positional embeddings shape:\", point_pos_embeddings.shape)\n",
        "\n",
        "        point_feature_embeddings = self.punctual_rain_rate_embed(points[..., 2:].float())\n",
        "        point_embeddings = torch.cat([point_feature_embeddings, point_pos_embeddings, point_pos_embeddings, self.point_modality.unsqueeze(0).expand(B, points.size(1), -1)], dim=-1)\n",
        "        # print(\"Final point embeddings shape:\", point_embeddings.shape)\n",
        "\n",
        "        # Embedding segments\n",
        "        seg_pos_embeddings0 = self.coord_embed(segments[..., :2].float())\n",
        "        seg_pos_embeddings1 = self.coord_embed(segments[..., 2:4].float())\n",
        "        segment_feature_embeddings = self.integrated_rain_rate_embed(segments[..., 4:].float())\n",
        "        segment_embeddings = torch.cat([segment_feature_embeddings, seg_pos_embeddings0, seg_pos_embeddings1, self.segment_modality.unsqueeze(0).expand(B, segments.size(1), -1)], dim=-1)\n",
        "        # print(\"Final segment embeddings shape:\", segment_embeddings.shape)\n",
        "\n",
        "        # Concatenate all embeddings\n",
        "        embeddings = torch.cat([patch_embeddings, point_embeddings, segment_embeddings], dim=1)\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.LayerNorm):\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "        nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "def trunc_normal_(tensor, mean=0, std=1):\n",
        "    nn.init.trunc_normal_(tensor, mean=mean, std=std)\n",
        "\n",
        "\n",
        "class FusionTransformer2dplus(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_size,\n",
        "        patch_size,\n",
        "        n_layers,\n",
        "        d_model,\n",
        "        d_ff,\n",
        "        n_heads,\n",
        "        channels=1,\n",
        "        nsteps=60\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.ue = UnifiedEmbedding2dplus(d_model, patch_size, channels, nsteps)\n",
        "        self.patch_size = patch_size\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        self.d_ff = d_ff\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [Block(d_model, n_heads, d_ff) for _ in range(n_layers)]\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.apply(init_weights)\n",
        "\n",
        "        self.decoder = Decoder(patch_size, d_model)\n",
        "\n",
        "    def forward(self, x, y, z):\n",
        "        # Embed signal\n",
        "        x = self.ue(x, y, z)  # (B, N, D)\n",
        "\n",
        "        # Process through each transformer block\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Apply final normalization\n",
        "        x = self.norm(x)\n",
        "        x = x[:,:256,:]\n",
        "\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlSZZSEwsXL1",
        "outputId": "f8ad7555-bcea-4b5b-8236-76203251d53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "model(noisy_images, point_measurements, segment_measurements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "3VpjVwiqnVPP",
        "outputId": "51549c57-adf0-4b5d-b623-2978916b92e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [36, 1, 4, 4], expected input[1, 12, 64, 64] to have 1 channels, but got 12 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-05df95c92d29>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_measurements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_measurements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-f09bf7985d8e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, z)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Embed signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, N, D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Process through each transformer block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-f09bf7985d8e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, points, segments)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Embedding patches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mpatch_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_feature_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# print(\"Patch embeddings shape:\", patch_embeddings.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [36, 1, 4, 4], expected input[1, 12, 64, 64] to have 1 channels, but got 12 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pE8_d-QJvSsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple / tracés\n",
        "images = set_tensor_values2(images, point_measurements)\n",
        "plot_images(images[0,...].cpu().numpy() + filters[0,...].cpu().numpy().sum(axis=0),\n",
        "            noisy_images[0,...].cpu().numpy(),\n",
        "            point_measurements[0,...].cpu().numpy(),\n",
        "            segment_measurements[0,...].cpu().numpy())"
      ],
      "metadata": {
        "id": "2UXxerZlPkI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CxGr8YXPn8DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TYTmlYkf-ZE",
        "outputId": "03045e5a-eede-4524-d28d-07949f70b876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1194, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}